<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="Marcos José Jiménez Henríquez" />

<meta name="date" content="2018-05-18" />

<title></title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/united.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<script src="site_libs/kePrint-0.0.1/kePrint.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />

</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>
<script>
$(document).ready(function () {
  window.initializeCodeFolding("hide" === "show");
});
</script>






<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Marcos Jiménez</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="about.html">Sobre mí</a>
</li>
<li>
  <a href="TFG.html">TFG</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">

<div class="btn-group pull-right">
<button type="button" class="btn btn-default btn-xs dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore"><center>
Trabajo de Fin de Grado <br> Prácticas estadísticas para investigadores en psicología (Versión extendida)
</center></h1>
<h4 class="author"><em>Marcos José Jiménez Henríquez</em></h4>
<h4 class="date"><em>2018-05-18</em></h4>

</div>

<div id="TOC">
<ul>
<li><a href="#abstract">Abstract</a></li>
<li><a href="#introduccion">Introducción</a></li>
<li><a href="#metodo-participantes-y-materiales">Método, participantes y materiales</a></li>
<li><a href="#setup"><em>Setup</em></a></li>
<li><a href="#hipotesis">Hipótesis</a></li>
<li><a href="#descripcion-de-los-efectos-naturales">Descripción de los efectos naturales</a></li>
<li><a href="#asunciones-para-identificar-los-efectos-naturales">Asunciones para identificar los efectos naturales</a></li>
<li><a href="#visualizacion-de-los-datos-y-asuncion-del-modelo-logistico-cumulativo">Visualización de los datos y asunción del modelo logístico cumulativo</a></li>
<li><a href="#modelos">Modelos</a></li>
<li><a href="#tests-de-equivalencia-superioridad-e-inferioridad">Tests de equivalencia, superioridad e inferioridad</a></li>
<li><a href="#estimacion-de-los-efectos-naturales-directos-indirectos-y-totales">Estimación de los efectos naturales directos, indirectos y totales</a></li>
<li><a href="#test-de-rigor">Test de rigor</a></li>
<li><a href="#factor-de-bayes">Factor de Bayes</a></li>
<li><a href="#factor-de-bayes-reportado-en-barberia2018">Factor de Bayes reportado en <span class="citation">Barberia (2018)</span></a></li>
<li><a href="#analisis-bayesiano">Análisis bayesiano</a></li>
<li><a href="#estimacion-de-los-efectos-naturales">Estimación de los efectos naturales</a></li>
<li><a href="#discusion">Discusión</a></li>
<li><a href="#paquetes-r-empleados">Paquetes R empleados</a></li>
<li><a href="#informacion-de-la-sesion">Información de la sesión</a></li>
<li><a href="#referencias">Referencias</a></li>
</ul>
</div>

<!--
<br>

<center> 
<h1>Prácticas estadísticas para investigadores en psicología (Versión extendida)</h1>
</center>

<br>
-->
<!--
<font size="4"> This is my text number 4</font> 
-->
<!--
load(file = "/home/marcos/Documentos/Projects/website/TFG_Workspace.RData")
-->
<p><br></p>
<div id="abstract" class="section level1">
<h1>Abstract</h1>
<p><br></p>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> El reciente proyecto de replicación consumado por el <span class="citation">Open Science Collaboration (2015)</span> ha intensificado el desarrollo de un gran número de trabajos que busca revertir la pérdida de credibilidad en la psicología. Las consecuencias más remarcables de este descontento se han materializado en un incremento de la adopción y promoción de prácticas de transparencia -preregistro, libre acceso a los artículos, datos y código-, en la denuncia de prácticas cuestionables y en políticas editoriales que abogan por la censura de reportes estadísticos clásicos, como los p-valores. Por otra parte, muchos autores han aprovechado este momento de insatisfacción para divulgar, más que nunca, su manera de construir e interpretar la evidencia científica. En este trabajo se ofrece una breve descripción e interpretación de algunos de los procedimientos estadísticos más comunes que aspiran a reemplazar el tan criticado <em>Null hypothesis significant testing (NHST)</em>. Para facilitar su comparación, estos métodos se contextualizan en el análisis de una intervención educativa que persigue reducir el desarrollo de ilusiones causales. Dado que el presente manuscrito no pretende únicamente exponer las distintas alternativas disponibles sino proporcionar los medios para que otros investigadores puedan implementarlas, el código de los análisis estadísticos, tablas y figuras son adjuntados.</p>
<p><br></p>
</div>
<div id="introduccion" class="section level1">
<h1>Introducción</h1>
<p><br> <!-- 
<font size="1">
</font> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
--></p>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> El reciente proyecto de replicación <span class="citation">Open Science Collaboration (2015)</span> ha intensificado el desarrollo de un gran número de trabajos que busca revertir la pérdida de credibilidad en la psicología y, aunque el criterio utilizado para considerar la replicación de un experimento resulta discutible<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a> <span class="citation">(S. Senn 2002)</span>, son ineludibles las carencias de una disciplina que adolece de los mismos problemas de los que Yates y Sterling advertían hace más de medio siglo:</p>
<blockquote>
<p>The emphasis on tests of significance and the consideration of the results of each experiment in isolation, have had the unfortunate consequence that scientific workers have often regarded the execution of a test of significance on an experiment as the ultimate objective. - <span class="citation">Yates (1951)</span></p>
</blockquote>
<blockquote>
<p>There is some evidence that in fields where statistical tests of significance are commonly used, research which yields nonsignificant results is not published. (…) The possibility such arises that the literature of such a field consists in substantial part of false conclusions. - <span class="citation">Sterling (1959)</span></p>
</blockquote>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> Así, hoy más que nunca la responsabilidad ha recaído sobre los métodos estadísticos tradicionales y la cultura editorial que incentiva el sesgo de publicación. Las consecuencias más remarcables de este descontento se han materializado en un incremento de la adopción y promoción de prácticas de transparencia como el preregistro y el libre acceso a los artículos, datos y código <span class="citation">(Lindsay 2015, <span class="citation">Munafò et al. (2017)</span>)</span>, en la denuncia de prácticas cuestionables <span class="citation">(Banks et al. 2016)</span> y en políticas editoriales que abogan por la censura de reportes estadísticos clásicos, como los p-valores <span class="citation">(Trafimow and Marks 2015)</span>. Por otra parte, muchos autores han aprovechado este momento de insatisfacción más que nunca para divulgar su manera de construir e interpretar la evidencia científica.</p>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> En este trabajo se ofrece una breve descripción e interpretación de algunos de los procedimientos estadísticos más comunes que aspiran a reemplazar el tan criticado <em>Null hypothesis significant testing</em> (NHST). Para facilitar su comparación, se contextualizan en el análisis de una intervención educativa que persigue reducir el desarrollo de ilusiones causales <span class="citation">(Barberia 2018)</span>.</p>
<p><br></p>
</div>
<div id="metodo-participantes-y-materiales" class="section level1">
<h1>Método, participantes y materiales</h1>
<p><br></p>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> El experimento descrito en <span class="citation">Barberia (2018)</span> comprende a 106 estudiantes de psicología aleatorizados a pasar por dos fases en distinto orden. La fase de intervención consistió en la inducción encubierta del efecto Forer y la aplicación de la tarea 2-4-6 de Wason <span class="citation">(Wason 1960)</span> con el objetivo de estimular sesgos de confirmación en las respuestas. Posteriormente, se describió la verdadera naturaleza de ambas tareas y se mencionaron algunas situaciones cotidianas en las que este tipo de sesgos confirmatorios desempeñan un relevante papel, como la lectura de horóscopos y los análisis grafológicos. Adicionalmente, se discutieron técnicas que lo contrarrestran, como intentar falsar o desconfirmar las hipótesis planteadas.</p>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> En la fase de evaluación se incitó a los participantes a actuar como doctores mientras valoraban si cada uno de 40 pacientes ficticios debía recibir un tratamiento farmacológico o no a través de un programa informático. Tras tomar esta decisión, recibían <em>feedback</em> indicando si el paciente había sanado. El programa informático fue programado para que, independientemente de suministrar el fármaco o no, la probabilidad de curación del paciente fuera del 75%. Este <em>setup</em> se debe, según los autores, a que una mayor frecuencia de sanaciones facilita el desarrollo de un mayor número de ilusiones causales sobre la eficacia del fármaco. Por último, los participantes puntuaron en una escala de 0 a 100 su convicción en la efectividad del fármaco.</p>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> Los investigadores hipotetizaron que los participantes que en primer lugar reciben la intervención son menos propensos a asignar un papel causal al medicamento ya que, siendo conscientes de las circuntancias que inducen el sesgo de confirmación, aplicarían una estrategia de naturaleza más desconfirmatoria durante la tarea. Es decir, según esta hipótesis, el número de veces que los participantes deciden suministrar el fármaco es menor tras pasar por la condición de intervención y opera como mediador entre la intervención educativa y la percepción sobre la eficacia del fármaco.</p>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> El <em>dataset</em> está disponible en el siguiente repositorio: <a href="https://osf.io/tzchd/">Open Science Framework</a></p>
<p><br></p>
</div>
<div id="setup" class="section level1">
<h1><em>Setup</em></h1>
<p><br></p>
<p>Cargamos los siguientes paquetes:</p>
<pre class="r"><code>lapply(c(&quot;tidyverse&quot;, &quot;rstan&quot;, &quot;bridgesampling&quot;, &quot;loo&quot;, &quot;shinystan&quot;, &quot;VGAM&quot;, &quot;ggplot2&quot;, &quot;bayesplot&quot;, &quot;grid&quot;, &quot;gridExtra&quot;, &quot;latex2exp&quot;, &quot;dagitty&quot;, &quot;ggdag&quot;, &quot;patchwork&quot;, &quot;knitr&quot;, &quot;kableExtra&quot;, &quot;BayesFactor&quot;), library, character.only = TRUE)</code></pre>
<p>Para los análisis bayesianos utilizaremos diferentes funciones con los que realizar diagnósticos del comportamiento de las cadenas Markov de Monte Carlo:</p>
<pre class="r"><code>source(&#39;https://raw.githubusercontent.com/betanalpha/knitr_case_studies/master/qr_regression/stan_utility.R&#39;)

# Para guardar los modelos que compilamos en C++:
rstan_options(auto_write = TRUE)
# Establecemos usar todos los núcleos del ordenador para tomar muestras de la distribución posterior:
options(mc.cores = parallel::detectCores())</code></pre>
<p><br></p>
</div>
<div id="hipotesis" class="section level1">
<h1>Hipótesis</h1>
<p><br></p>
<pre class="r"><code>Causal_Graph &lt;- dagify(xi ~ X + M,
                       M ~ xi,
                         M ~ X,
                         Y ~ xi,
                         labels = c(&quot;xi&quot; = &quot;Nivel de\n convicción&quot;, 
                                    &quot;X&quot; = &quot;Intervención&quot;,
                                    &quot;M&quot; = &quot;Administración\n del fármaco&quot;,
                                    &quot;Y&quot; = &quot;Puntuación\n observada&quot;),
                         latent = &quot;xi&quot;,
                         exposure = &quot;X&quot;,
                         outcome = &quot;Y&quot;,
              coords = list(x = c(Y = 3.5, xi = 3, X = 1, M = 2),
              y = c(Y = 1, xi = 1, X = 1, M = 2)))
dag1 &lt;- ggdag(Causal_Graph, node_size = 20, text = F) + # use_labels = &quot;label&quot;
  geom_dag_node(aes(x = 2, y = 2), internal_colour = &quot;white&quot;, color = &quot;white&quot;) +
  geom_dag_node(aes(x = 3, y = 1), internal_colour = &quot;grey&quot;, color = &quot;grey&quot;) +
  geom_segment(aes(x = 2.35, xend = 2.2, y = 2.15, yend = 2.05), arrow = arrow(length = unit(2, &quot;mm&quot;), type=&#39;closed&#39;)) +
  geom_segment(aes(x = 3.25, xend = 3.1, y = 1.3, yend = 1.2), arrow = arrow(length = unit(2, &quot;mm&quot;), type=&#39;closed&#39;)) +
  geom_dag_edges_link(arrow = grid::arrow(length = grid::unit(2, &quot;mm&quot;), type = &quot;closed&quot;)) +
  geom_curve(mapping = aes(x = 2.55, xend = 3.35, y = 2.2, yend = 1.45), curvature = -0.5, angle = 90, linetype = &quot;dashed&quot;,
             size = 0.15) +
  annotate(&quot;text&quot;, x = 2.45, y = 2.15, label = TeX(&#39;$\\epsilon_M$&#39;), parse=T, colour = &quot;black&quot;, size = 4.5) +
  annotate(&quot;text&quot;, x = 3.35, y = 1.35, label = TeX(&#39;$\\epsilon_{\\xi}$&#39;), parse=T, colour = &quot;black&quot;, size = 4.5) +
  annotate(&quot;text&quot;, x = 1.35, y = 1.55, label = TeX(&#39;$\\beta_{\\,XM}$&#39;), parse=T, colour = &quot;black&quot;, size = 4.5) +
  annotate(&quot;text&quot;, x = 2.65, y = 1.55, label =  TeX(&#39;$\\beta\\prime_{M\\xi}$&#39;), parse=T, colour = &quot;black&quot;, size = 4.5) +
  annotate(&quot;text&quot;, x = 2, y = 0.85, label = TeX(&#39;$\\beta\\prime_{X\\xi}$&#39;), parse=T, colour = &quot;black&quot;, size = 4.5) +
  annotate(&quot;text&quot;, x = 3, y = 1, label = TeX(&#39;$\\xi$&#39;), parse=T, colour = &quot;black&quot;, size = 6) +
  annotate(&quot;text&quot;, x = 3.5, y = 1, label =  &quot;Y&quot;, parse=F, colour = &quot;white&quot;, size = 5) +
  annotate(&quot;text&quot;, x = 1, y = 1, label = &quot;X&quot;, parse=F, colour = &quot;white&quot;, size = 5) +
  annotate(&quot;text&quot;, x = 2, y = 2, label = &quot;M&quot;, parse=F, colour = &quot;black&quot;, size = 5) +
  scale_y_continuous(limits = c(0.85, 2.2)) + scale_x_continuous(limits = c(0.95, 3.55)) +
  theme(axis.line=element_blank(),axis.text.x=element_blank(),
        axis.text.y=element_blank(),axis.ticks=element_blank(),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),legend.position=&quot;none&quot;,
        panel.background=element_blank(),panel.border=element_blank(),panel.grid.major=element_blank(),
        panel.grid.minor=element_blank(),plot.background=element_blank())
dag1</code></pre>
<p><img src="TFG_files/figure-html/DAG_1-1.png" width="480" style="display: block; margin: auto;" /></p>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> La figura (<em>directed acyclic graph</em>) muestra los efectos causales que se pretenden estimar. <span class="math inline">\(X\)</span> representa la exposición a la intervención educativa, <span class="math inline">\(M\)</span> es el efecto mediador que supone la decisión de administrar o no el fármaco, <span class="math inline">\(\xi\)</span> es la percepción de eficacia que los participantes atribuyen a dicho fármaco (variable latente) e <span class="math inline">\(Y\)</span> es su indicador, la puntuación observada. Los errores <span class="math inline">\(\varepsilon_M\)</span> y <span class="math inline">\(\varepsilon^\prime_{\xi}\)</span> se muestan correlacionados ante la posibilidad de que una variable no identificada afecte a <span class="math inline">\(M\)</span> y <span class="math inline">\(\xi\)</span> y <span class="math inline">\(\beta^\prime_{M\xi}\)</span> se corresponde con el efecto de <span class="math inline">\(M\)</span> en <span class="math inline">\(\xi\)</span>. El efecto de <span class="math inline">\(\xi\)</span> sobre <span class="math inline">\(M\)</span> (nótese que el trazo que les une es bidireccional) se debe a que es razonable pensar que la probabilidad de administrar el fármaco está influida por la propia percepción de eficacia que va progresando durante el desarrollo de la prueba.</p>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> Por otro lado, es importante resaltar la distinción entre <span class="math inline">\(\xi\)</span> e <span class="math inline">\(Y\)</span> ya que no existe ninguna teoría ni investigación que permita establecer un isomorfismo entre ambas variables. Tomar dicha asunción equivale a presuponer que la variable latente es cuantitativa y correctamente representada en la escala de intervalo <span class="math inline">\([0, 100]\)</span> establecida por los investigadores. Por varios motivos, la escala original se ha transformado en otra compuesta de cinco categorías ordinales que pueden ser interpretadas de la siguiente manera: considerable convicción en la ineficacia del fármaco <span class="math inline">\([0, 20)\)</span>; convicción parcial en la ineficacia del fármaco <span class="math inline">\([20, 40)\)</span>; duda <span class="math inline">\([40, 60)\)</span>, convicción parcial en la eficacia del fármaco <span class="math inline">\([60, 80)\)</span> y considerable convicción en la eficacia del fármaco <span class="math inline">\([80, 100]\)</span>.</p>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> Cargamos y transformamos los datos:</p>
<pre class="r"><code>data &lt;- read.csv(&quot;https://osf.io/tzchd/download&quot;, sep = &quot;;&quot;)
mydata &lt;- data.frame(id = 1:106)
mydata$Indicador[data$Causal_Judgment &gt;= 0] &lt;- 1
mydata$Indicador[data$Causal_Judgment &gt;= 20] &lt;- 2
mydata$Indicador[data$Causal_Judgment &gt;= 40] &lt;- 3
mydata$Indicador[data$Causal_Judgment &gt;= 60] &lt;- 4
mydata$Indicador[data$Causal_Judgment &gt;= 80] &lt;- 5
mydata$Grupo[data$GroupText == &quot;intervention&quot;] &lt;- 1 # Intervención educativa
mydata$Grupo[data$GroupText == &quot;control&quot;] &lt;- 0 # No intervención
mydata$Si &lt;- data$Percentage_Responses * 0.4 # Número de administraciones del fármaco
mydata$No &lt;- 40 - mydata$Si # Número de veces que se decide no administrar el fármaco</code></pre>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> Información del dataset:</p>
<pre class="r"><code>str(mydata)
## &#39;data.frame&#39;:    106 obs. of  5 variables:
##  $ id       : int  1 2 3 4 5 6 7 8 9 10 ...
##  $ Indicador: num  4 1 2 1 1 4 1 3 1 1 ...
##  $ Grupo    : num  1 1 1 1 1 1 1 1 1 1 ...
##  $ Si       : num  23 9 10 17 18 22 10 22 14 5 ...
##  $ No       : num  17 31 30 23 22 18 30 18 26 35 ...

# Cantidad de participantes que selecciona cada categoría:
table(mydata$Indicador)
## 
##  1  2  3  4  5 
## 28 10 28 29 11

# En el grupo de intervención:
table(mydata$Indicador[mydata$Grupo == 1])
## 
##  1  2  3  4  5 
## 19  4 12 11  1

# En el grupo de no intervención:
table(mydata$Indicador[mydata$Grupo == 0])
## 
##  1  2  3  4  5 
##  9  6 16 18 10</code></pre>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> La elección de modelar los datos como una función ordinal es más adecuada por las siguientes razones:</p>
<ol style="list-style-type: decimal">
<li>Las respuestas observadas no se distribuyen a lo largo de la recta real sino que toman valores enteros. Si el mecanismo que genera los datos correspondiera a una distribución de densidad se esperarían observar datos con decimales.</li>
<li>Es implausible que las diferencias numéricas entre los participantes representen su percepción sobre la eficacia del fármaco a escala de intervalo <span class="citation">(Morris, Grice, and Cox 2017)</span>. Esto implicaría que disponen de la capacidad para distinguir una infinidad de estados de convicción y que pueden representarlos adecuadamente en la recta real.</li>
<li>Es mucho más realista asumir que los participantes solo pueden distinguir sus niveles de convicción en unas pocas categorías.</li>
<li>La regresión ordinal cumulativa no impone una distribución concreta para los datos, permitiendo modelar fácilmente el considerable número de ceros observados y es compatible con la asunción de que la percepción sobre la eficacia del fármaco es una variable latente continua.</li>
</ol>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> De esta manera, aunque el análisis original utilizó el método de mínimos cuadrados, aquí se ha decidido aplicar una regresión logística cumulativa parcial<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a> <span class="citation">(Peterson and Harrell 1990)</span> en el que se estima un parámetro <span class="math inline">\(\beta^\prime_{XY_j}\)</span> diferente para cada punto de corte <span class="math inline">\(j\)</span>:</p>
<p><span class="math display">\[ \log\left(\frac{\text{Pr}(Y \le j)} {\text{Pr}(Y &gt; j)}\right) = \alpha_j - X \beta^\prime_{XY_j} - M \beta^\prime_{MY} \]</span> donde <span class="math inline">\(Y\)</span> representa las observaciones transformadas.</p>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> Reemplazando la variable latente por su indicador, la siguiente Figura muestra el modelo empírico con los parámetros que finalmente se estiman.</p>
<pre class="r"><code>Causal_Graph_Empirical &lt;- dagify(Y ~ X + M,
              M ~ X,
              labels = c(&quot;X&quot; = &quot;Intervención&quot;,
                         &quot;M&quot; = &quot;Administración\n del fármaco&quot;,
                         &quot;Y&quot; = &quot;Puntuación\n observada&quot;),
              exposure = &quot;X&quot;,
              outcome = &quot;Y&quot;,
              coords = list(x = c(Y = 3, X = 1, M = 2),
                            y = c(Y = 1, X = 1, M = 2))) 
dag2 &lt;- ggdag(Causal_Graph_Empirical, node_size = 20, text = F) + # use_labels = &quot;label&quot;
  geom_dag_node(aes(x = 2, y = 2), internal_colour = &quot;white&quot;, color = &quot;white&quot;) +
  geom_curve(mapping = aes(x = 2.55, xend = 3.35, y = 2.2, yend = 1.45), curvature = -0.5, angle = 90, linetype = &quot;dashed&quot;,
             size = 0.15) +
  annotate(&quot;text&quot;, x = 2.45, y = 2.15, label = TeX(&#39;$\\epsilon_M$&#39;), parse=T, colour = &quot;black&quot;, size = 4.5) +
  annotate(&quot;text&quot;, x = 3.35, y = 1.35, label = TeX(&#39;$\\epsilon\\prime_{Y}$&#39;), parse=T, colour = &quot;black&quot;, size = 4.5) +
  annotate(&quot;text&quot;, x = 1.35, y = 1.55, label = TeX(&#39;$\\beta_{\\,XM}$&#39;), parse=T, colour = &quot;black&quot;, size = 4.5) +
  annotate(&quot;text&quot;, x = 2.65, y = 1.55, label = TeX(&#39;$\\beta\\prime_{MY}$&#39;), parse=T, colour = &quot;black&quot;, size = 4.5) +
  annotate(&quot;text&quot;, x = 2, y = 0.85, label = TeX(&#39;$\\beta\\prime_{XY_j}$&#39;), parse=T, colour = &quot;black&quot;, size = 4.5) +
  annotate(&quot;text&quot;, x = 3, y = 1, label =  &quot;Y&quot;, parse=F, colour = &quot;white&quot;, size = 5) +
  annotate(&quot;text&quot;, x = 1, y = 1, label = &quot;X&quot;, parse=F, colour = &quot;white&quot;, size = 5) +
  annotate(&quot;text&quot;, x = 2, y = 2, label = &quot;M&quot;, parse=F, colour = &quot;black&quot;, size = 5) +
  scale_y_continuous(limits = c(0.85, 2.2)) + scale_x_continuous(limits = c(0.9, 3.35)) +
  theme(axis.line=element_blank(),axis.text.x=element_blank(),
        axis.text.y=element_blank(),axis.ticks=element_blank(),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),legend.position=&quot;none&quot;,
        panel.background=element_blank(),panel.border=element_blank(),panel.grid.major=element_blank(),
        panel.grid.minor=element_blank(),plot.background=element_blank()) + 
  geom_segment(aes(x = 2.35, xend = 2.2, y = 2.15, yend = 2.05), arrow = arrow(length = unit(2, &quot;mm&quot;), type=&#39;closed&#39;)) +
  geom_segment(aes(x = 3.25, xend = 3.1, y = 1.3, yend = 1.2), arrow = arrow(length = unit(2, &quot;mm&quot;), type=&#39;closed&#39;)) +
  geom_dag_edges_link(arrow = grid::arrow(length = grid::unit(2, &quot;mm&quot;), type = &quot;closed&quot;))
dag2</code></pre>
<p><img src="TFG_files/figure-html/DAG_2-1.png" width="480" style="display: block; margin: auto;" /></p>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> Para la regresión de <span class="math inline">\(M\)</span> en <span class="math inline">\(X\)</span> (trayectoria con el coeficiente <span class="math inline">\(\beta_{XM}\)</span>) se adopta un modelo betabinomial que acomoda la sobredispersión observada en <span class="math inline">\(M\)</span>. De esta manera, la probabilidad de la función binomial pasa a considerarse una variable aleatoria que sigue una distribución beta. Este modelo es adecuado porque cabe esperar que las decisiones de administrar el medicamento estén relacionadas en un mismo participante. Es decir, la probabilidad de que un participante decida administrar o no el fármaco depende de sus previas decisiones.</p>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> Finalmente, para el análisis mediacional se ha empleado la inferencia paramétrica descrita en <span class="citation">Imai, Keele, and Tingley (2010)</span> y <span class="citation">VanderWeele, Zhang, and Lim (2016)</span>, que descansa en la aproximación contrafactual de Judea Pearl <span class="citation">(Pearl 2014)</span>, quien descompone el efecto total de la intervención en efectos naturales directos (NDE) e indirectos (NIE).</p>
<p><br></p>
</div>
<div id="descripcion-de-los-efectos-naturales" class="section level1">
<h1>Descripción de los efectos naturales</h1>
<p><br></p>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> Efecto natural directo (NDE): impacto de la intervención educativa en el indicador de la percepción de eficacia si los participantes decidieran admistrar el fármaco como si no hubieran pasado por ella.</p>
<p><span class="math display">\[ NDE = \text{E}[Y_{X_1, M_0} - Y_{X_0, M_0}]  \]</span></p>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> Efecto natural indirecto (NIE): impacto de la administración del fármaco en el indicador de la percepción de eficacia si los participantes no hubieran pasado por la condición de intervención.</p>
<p><span class="math display">\[ NIE = \text{E}[Y_{X_0, M_1} - Y_{X_0, M_0}]  \]</span></p>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> Y el efecto total de la intervención educativa (TE) es</p>
<p><span class="math display">\[ TE = \text{E}[Y_{X_1} - Y_{X_0}] = NDE + NIE \]</span></p>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> Estos efectos serán estimados siguiendo el método paramétrico descrito en <span class="citation">Imai, Keele, and Tingley (2010)</span>. Básicamente, consiste en ajustar un modelo que regresa la intervención <span class="math inline">\(X\)</span> en la variable mediacional <span class="math inline">\(M\)</span> y otro regresando el indicador <span class="math inline">\(Y\)</span> en ambas. Luego, con los coeficientes estimados se simulan datos de las condiciones contrafactuales especificadas anteriormente para aproximar las esperanzas matemáticas.</p>
<p><br></p>
</div>
<div id="asunciones-para-identificar-los-efectos-naturales" class="section level1">
<h1>Asunciones para identificar los efectos naturales</h1>
<p><br></p>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> Los efectos naturales directo (NDE) e indirecto (NIE) son identificados si (a) <span class="math inline">\(X\)</span> e <span class="math inline">\(Y^{xm}\)</span> son independientes dado un set <span class="math inline">\(C\)</span> de covariables que incluye todas las variables confusoras, (b) <span class="math inline">\(M^x\)</span> e <span class="math inline">\(Y^{x^\prime m}\)</span> son independientes dado X y C, (c) <span class="math inline">\(X\)</span> y <span class="math inline">\(M^x\)</span> son independientes dado C y (d) <span class="math inline">\(M^x\)</span> e <span class="math inline">\(Y^{x^\prime m}\)</span> son independientes dado <span class="math inline">\(C\)</span> <span class="citation">(VanderWeele, Zhang, and Lim 2016)</span>.</p>
<p><span class="math display">\[ \text{(a)} \,\,\, Y^{x m} \amalg X \, | \, C \]</span> <span class="math display">\[ \text{(b)} \,\,\, Y^{x^\prime m} \amalg M^x \, | \, X, C \]</span> <span class="math display">\[ \text{(c)} \,\,\, M^x \amalg X \, | \, C \]</span> <span class="math display">\[ \text{(d)} \,\,\,  Y^{x^\prime m} \amalg M^x \, | \, C \]</span></p>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> Es importante destacar que los superíndices indican situaciones contrafactuales. <span class="math inline">\(M \amalg X\)</span> no equivale a <span class="math inline">\(M^x \amalg X\)</span>. El primero representa la independencia entre la observación <span class="math inline">\(M\)</span> y la observación <span class="math inline">\(X\)</span> mientras que el segundo señala que el valor <span class="math inline">\(M\)</span> bajo todo posible tratamiento <span class="math inline">\(x\)</span> hubiera sido independiente a la observación <span class="math inline">\(X\)</span>.</p>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> Las asunciones (a) y (c) son automáticamente satisfechas por la aleatorización a la intervención. Sin embargo, las asunciones (b) y (d) no son falsables a menos que la variable mediacional sea aleatorizada o se incluya en la regresión todas las variables confusoras. En este experimento <span class="math inline">\(M\)</span> no fue aleatorizado y en el <em>dataset</em> no hay covariables con las que ajustar el modelo, por lo que estas últimas asunciones permanecerán infalsables.</p>
<p><br></p>
</div>
<div id="visualizacion-de-los-datos-y-asuncion-del-modelo-logistico-cumulativo" class="section level1">
<h1>Visualización de los datos y asunción del modelo logístico cumulativo</h1>
<p><br></p>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> Visualización preliminar de la relación entre el indicador y las covariables:</p>
<pre class="r"><code>data_Grupo_1 &lt;- mydata %&gt;% filter(Grupo == 1) # Datos del grupo que recibe la intervención.
data_Grupo_0 &lt;- mydata %&gt;% filter(Grupo == 0) # Datos del grupo que no recibe la intervención.
plot1 &lt;- ggplot(data_Grupo_1) + theme_gray() +
  geom_boxplot(aes(x = 3, width = 1.5, ymin = quantile(Si, 0.05), lower = quantile(Si, 0.25), middle = quantile(Si, 0.5), 
                   upper = quantile(Si, 0.75), ymax = quantile(Si, 0.95)), stat = &quot;identity&quot;) +
  geom_point(aes(x = Indicador, y = Si), alpha = 0.3, size = 2) +
  coord_flip() +
  labs(title = NULL) +
  scale_y_continuous(name = NULL, limits = c(-0.5, 40.5), seq(0, 40, 5)) +
  scale_x_continuous(name = NULL, expand = c(0.03, 0), limits = c(0.5, 5.5), seq(1, 5, 1)) +
  theme(axis.text.x = element_text(size = 11), axis.title.x = element_text(size = 14),
        axis.text.y = element_text(size = 11), axis.title.y = element_text(size = 14)) +
  theme(axis.text.x = element_text(margin = unit(c(3, 0, 0, 0), &quot;mm&quot;), colour = &quot;black&quot;),
        axis.text.y = element_text(margin = unit(c(0, 3, 0, 0), &quot;mm&quot;), colour = &quot;black&quot;)) +
  theme(axis.ticks.x = element_line(size = 0.6), 
        axis.ticks.y = element_line(size = 0.6)) +
  theme(axis.title.x = element_text(margin = unit(c(5, 0, 0, 0), &quot;mm&quot;), colour = &quot;black&quot;),
        axis.title.y = element_text(margin = unit(c(0, 5, 0, 0), &quot;mm&quot;), colour = &quot;black&quot;)) +
    theme(plot.margin = unit(c(0.5, 0 , 0.25, 0.5), &quot;cm&quot;)) +
  theme(panel.border = element_rect(fill = NA), axis.ticks.length = unit(0.2, &quot;cm&quot;)) +
  annotate(&quot;text&quot;, x = 4.5, y = 4, label = &quot;Intervención&quot;, parse = F, colour = &quot;black&quot;, size = 5)

plot2 &lt;- ggplot(data_Grupo_0) + theme_gray() +
  geom_boxplot(aes(x = 3, width = 1.5, ymin = quantile(Si, 0.05), lower = quantile(Si, 0.25), middle = quantile(Si, 0.5), 
                   upper = quantile(Si, 0.75), ymax = quantile(Si, 0.95)), stat = &quot;identity&quot;) +
  geom_point(aes(x = Indicador, y = Si), alpha = 0.3, size = 2) +
  coord_flip() +
  labs(title = NULL) +
  scale_y_continuous(name = NULL, limits = c(-0.5, 40.5), seq(0, 40, 5)) +
  scale_x_continuous(name = NULL, expand = c(0.03, 0), limits = c(0.5, 5.5), seq(1, 5, 1)) +
  theme(axis.text.x = element_text(size = 11), axis.title.x = element_text(size = 14),
        axis.text.y = element_text(size = 11), axis.title.y = element_text(size = 14)) +
  theme(axis.text.x = element_text(margin = unit(c(3, 0, 0, 0), &quot;mm&quot;), colour = &quot;black&quot;),
        axis.text.y = element_text(margin = unit(c(0, 3, 0, 0), &quot;mm&quot;), colour = &quot;black&quot;)) +
  theme(axis.ticks.x = element_line(size = 0.6), 
        axis.ticks.y = element_line(size = 0.6)) +
  theme(axis.title.x = element_text(margin = unit(c(5, 0, 0, 0), &quot;mm&quot;), colour = &quot;black&quot;),
        axis.title.y = element_text(margin = unit(c(0, 5, 0, 0), &quot;mm&quot;), colour = &quot;black&quot;)) +
  theme(plot.margin = unit(c(0.25, 0 , 0.5, 0.5), &quot;cm&quot;)) +
  theme(panel.border = element_rect(fill = NA), axis.ticks.length = unit(0.2, &quot;cm&quot;)) +
  annotate(&quot;text&quot;, x = 4.5, y = 4, label = &quot;No intervención&quot;, parse = F, colour = &quot;black&quot;, size = 5)

grid.arrange(plot1, plot2, bottom = textGrob(&quot;Número de administraciones del fármaco&quot;, vjust = 0, gp = gpar(fontsize = 14)), 
        left = textGrob(&quot;Indicador de la percepción de eficacia&quot;, gp = gpar(fontsize = 14), rot = 90, vjust = 0.1, hjust = 0.4))</code></pre>
<p><img src="TFG_files/figure-html/Visualization2-1.png" width="768" style="display: block; margin: auto;" /></p>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> Contrastamos la asunción de que el coeficiente de la intervención y el del número de administraciones del fármaco son cumulativamente constantes a lo largo de las categorías (<em>cumulative odds assumption</em>) aplicando una regresión binomial para cada punto de corte:</p>
<pre class="r"><code>odds_grupo &lt;- NA; upper.limit_grupo &lt;- NA; lower.limit_grupo &lt;- NA
odds_Si &lt;- NA; upper.limit_Si &lt;- NA; lower.limit_Si &lt;- NA
for(i in 1:4) {
  binomial_model &lt;- summary(vglm(I(as.numeric(Indicador) &lt;= i) ~ Grupo + Si, family = binomialff(dispersion = 1), data = mydata))@coef3
  
  # Razones de momios para la intervención:
  odds_grupo[i] &lt;- exp(binomial_model[&quot;Grupo&quot;, &quot;Estimate&quot;])
  upper.limit_grupo[i] &lt;- exp(binomial_model[&quot;Grupo&quot;, &quot;Estimate&quot;] +  binomial_model[&quot;Grupo&quot;, &quot;Std. Error&quot;] * qnorm(0.975))
  lower.limit_grupo[i] &lt;- exp(binomial_model[&quot;Grupo&quot;, &quot;Estimate&quot;] +  binomial_model[&quot;Grupo&quot;, &quot;Std. Error&quot;] * qnorm(1-0.975))
  
  # Razones de momios para el número de administraciones del fármaco:
  odds_Si[i] &lt;- exp(binomial_model[&quot;Si&quot;, &quot;Estimate&quot;])
    upper.limit_Si[i] &lt;- exp(binomial_model[&quot;Si&quot;, &quot;Estimate&quot;] +  binomial_model[&quot;Si&quot;, &quot;Std. Error&quot;] * qnorm(0.975))
    lower.limit_Si[i] &lt;- exp(binomial_model[&quot;Si&quot;, &quot;Estimate&quot;] +  binomial_model[&quot;Si&quot;, &quot;Std. Error&quot;] * qnorm(1-0.975))
}

binomial_coefs_Grupo &lt;- t(rbind(upper.limit_grupo, odds_grupo, lower.limit_grupo))
colnames(binomial_coefs_Grupo) &lt;- c(&quot;2.5%&quot;, &quot;Estimación&quot;, &quot;97.5%&quot;)
rownames(binomial_coefs_Grupo) &lt;- paste(&quot;Pr(Y) &lt;=&quot;, 1:4, sep = &quot; &quot;)

binomial_coefs_Si &lt;- t(rbind(upper.limit_Si, odds_Si, lower.limit_Si))
colnames(binomial_coefs_Si) &lt;- c(&quot;2.5%&quot;, &quot;Estimación&quot;, &quot;97.5%&quot;)
rownames(binomial_coefs_Si) &lt;- paste(&quot;Pr(Y) &lt;=&quot;, 1:4, sep = &quot; &quot;)

kable(binomial_coefs_Grupo, digits = 3, caption = &quot;Coeficientes para la intervención&quot;, align = &quot;c&quot;) %&gt;%
  kable_styling(bootstrap_options = &quot;striped&quot;, full_width = F)

kable(1 / binomial_coefs_Si, digits = 3, caption = &quot;Coeficientes para el número de administraciones del fármaco&quot;, align = &quot;c&quot;) %&gt;%
  kable_styling(bootstrap_options = &quot;striped&quot;, full_width = F)</code></pre>
<table class="table table-striped" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
Coeficientes para la intervención
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:center;">
2.5%
</th>
<th style="text-align:center;">
Estimación
</th>
<th style="text-align:center;">
97.5%
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Pr(Y) &lt;= 1
</td>
<td style="text-align:center;">
5.551
</td>
<td style="text-align:center;">
1.868
</td>
<td style="text-align:center;">
0.628
</td>
</tr>
<tr>
<td style="text-align:left;">
Pr(Y) &lt;= 2
</td>
<td style="text-align:center;">
3.287
</td>
<td style="text-align:center;">
1.161
</td>
<td style="text-align:center;">
0.410
</td>
</tr>
<tr>
<td style="text-align:left;">
Pr(Y) &lt;= 3
</td>
<td style="text-align:center;">
2.918
</td>
<td style="text-align:center;">
1.012
</td>
<td style="text-align:center;">
0.351
</td>
</tr>
<tr>
<td style="text-align:left;">
Pr(Y) &lt;= 4
</td>
<td style="text-align:center;">
33.268
</td>
<td style="text-align:center;">
3.408
</td>
<td style="text-align:center;">
0.349
</td>
</tr>
</tbody>
</table>
<table class="table table-striped" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
Coeficientes para el número de administraciones del fármaco
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:center;">
2.5%
</th>
<th style="text-align:center;">
Estimación
</th>
<th style="text-align:center;">
97.5%
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Pr(Y) &lt;= 1
</td>
<td style="text-align:center;">
1.096
</td>
<td style="text-align:center;">
1.184
</td>
<td style="text-align:center;">
1.280
</td>
</tr>
<tr>
<td style="text-align:left;">
Pr(Y) &lt;= 2
</td>
<td style="text-align:center;">
1.127
</td>
<td style="text-align:center;">
1.234
</td>
<td style="text-align:center;">
1.351
</td>
</tr>
<tr>
<td style="text-align:left;">
Pr(Y) &lt;= 3
</td>
<td style="text-align:center;">
1.142
</td>
<td style="text-align:center;">
1.262
</td>
<td style="text-align:center;">
1.395
</td>
</tr>
<tr>
<td style="text-align:left;">
Pr(Y) &lt;= 4
</td>
<td style="text-align:center;">
1.110
</td>
<td style="text-align:center;">
1.252
</td>
<td style="text-align:center;">
1.414
</td>
</tr>
</tbody>
</table>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> Como podemos observar, las estimaciones de las razones de momios para la intervención son muy diferentes o presentan un error de medida demasiado amplio como para asumir su igualdad. Sin embargo, las razones de momios para el número de administraciones del fármaco son bastante similares y los intervalos de confianza no son excesivamente amplios. Por tanto, un modelo cumulativo parcial en el que emplear un parámetro distinto para la variable intervencional por cada punto de corte es apropiado.</p>
<p><br></p>
</div>
<div id="modelos" class="section level1">
<h1>Modelos</h1>
<p><br></p>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> En primer lugar, debemos estimar el efecto de la intervención educativa en el número de administraciones del fármaco. Sin embargo, no podemos emplear un simple modelo binomial debido a la presencia de sobredispersión, seguramente debida a que los ensayos <em>bernoulli</em> de cada participante se encuentran correlacionados y dependen, en parte, de la percepción de eficacia del fármaco que el participante va desarrollando durante la ejecución del experimento (como se muestra en el <em>directed acyclic graph</em>):</p>
<pre class="r"><code>
binomial_model &lt;- glm(cbind(Si, No) ~ Grupo, family = binomial, data = mydata)

# Si no existiera sobredispersión, los grados de libertad residuales del modelo no deberían ser sorprendentemente distintos a la suma de los cuadrados residuales de Pearson:
residuals &lt;- resid(binomial_model, type = &quot;pearson&quot;)
sum(residuals^2) / binomial_model$df.residual
# Esta razón indica que la varianza observada es hasta 8.35 veces superior a la esperada por el modelo binomial.</code></pre>
<pre><code>## [1] 8.354068</code></pre>
<pre class="r"><code># Una opción es reajustar el modelo con un parámetro añadido que acomode esta sobredispersión (modelo quasibinomial):
modelo_quasibinomial &lt;- glm(cbind(Si, No) ~ Grupo, family = quasibinomial, data = mydata)
summary(modelo_quasibinomial)$dispersion
# Este modelo da lugar a las mismas estimaciones pero con intervalos de confianza más amplios.
# Sin embargo, el modelo betabinomial es teóricamente más adecuado porque permite que la probabilidad de los participantes de decidir administrar el fármaco sea una distribución en lugar de un valor fijo.</code></pre>
<pre><code>## [1] 8.354068</code></pre>
<p>Utilizaremos un modelo betabinomial:</p>
<p><span class="math display">\[ k \, | \, n \sim \text{Binomial}(\theta, \text{n})\]</span> <span class="math display">\[ \theta \sim \text{Beta}(\alpha, \beta) \]</span> donde <span class="math inline">\(k\)</span> se corresponde con el número de administraciones del fármaco.</p>
<pre class="r"><code># Ajustamos el modelo betabinomial:
modelo_XM &lt;- vglm(cbind(Si, No) ~ Grupo, family = betabinomial, data = mydata)
odds.ratios_XM &lt;- exp(cbind(coef(modelo_XM), confint(modelo_XM))) # Los coeficientes en razones de momios.
summary_modelo_XM &lt;- summary(modelo_XM)@coef3 # Tabla de coeficientes en logaritmos.
rho &lt;- summary(modelo_XM)@misc$rho[1] # Estimada correlación entre las decisiones de un mismo participante (intraclass correlation).

odds.ratios_XM</code></pre>
<pre><code>##                             2.5 %    97.5 %
## (Intercept):1 1.6237295 1.2630867 2.0873448
## (Intercept):2 0.2774607 0.2101624 0.3663093
## Grupo         0.4549559 0.3125152 0.6623194</code></pre>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> En segundo lugar, utilizaremos un modelo logístico cumulativo parcial para regresar el indicador en la intervención y el número de administraciones del fármaco:</p>
<p><span class="math display">\[\text{logit}(Y \le j) = \alpha_j - X\beta^\prime_{XY_j} - M\beta^\prime_{MY}\]</span></p>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> Para comprobar si el efecto de la decisión de administrar el fármaco no es lineal, ajustamos el modelo ordinal con un término <em>spline</em> y comprobamos si su grados de libertad difieren de 1:</p>
<pre class="r"><code>summary(vgam(Indicador ~ Grupo + sm.os(Si), family = cumulative(parallel = F ~ Grupo), data = mydata))
## 
## Call:
## vgam(formula = Indicador ~ Grupo + sm.os(Si), family = cumulative(parallel = F ~ 
##     Grupo), data = mydata)
## 
## 
## Pearson residuals:
##                    Min        1Q   Median      3Q    Max
## logit(P[Y&lt;=1]) -2.5061 -0.262339 -0.13937 0.21770 3.1371
## logit(P[Y&lt;=2]) -2.7846 -0.505096 -0.11688 0.29958 2.6491
## logit(P[Y&lt;=3]) -3.2763 -0.389215  0.15002 0.58013 2.6374
## logit(P[Y&lt;=4]) -5.4007  0.043515  0.11207 0.21813 1.4544
## 
## Parametric coefficients: 
##               Estimate Std. Error z value  Pr(&gt;|z|)    
## (Intercept):1 -1.87531    0.42770 -4.3846 1.162e-05 ***
## (Intercept):2 -1.04935    0.35366 -2.9671  0.003006 ** 
## (Intercept):3  0.67445    0.32139  2.0986  0.035854 *  
## (Intercept):4  3.02697    0.48783  6.2049 5.472e-10 ***
## Grupo:1        0.50883    0.56506  0.9005  0.367861    
## Grupo:2        0.23742    0.50637  0.4689  0.639159    
## Grupo:3        0.24412    0.50694  0.4815  0.630127    
## Grupo:4        1.24675    1.12416  1.1090  0.267411    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Approximate significance of smooth terms:
##               edf Est.rank Chi.sq   p-value    
## sm.os(Si) 0.99511        2 44.256 2.454e-10 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Number of linear/additive predictors:    4 
## 
## Names of linear/additive predictors: logit(P[Y&lt;=1]), logit(P[Y&lt;=2]), logit(P[Y&lt;=3]), logit(P[Y&lt;=4]) 
## 
## Dispersion Parameter for cumulative family:   1
## 
## Residual deviance:  245.0071 on 425 degrees of freedom
## 
## Log-likelihood: -122.5036 on 425 degrees of freedom
## 
## Number of outer iterations:  6 
## 
## Number of IRLS iterations at final outer iteration:  2</code></pre>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> Los grados de libertad son aproximadamente 1, por lo que utilizaremos un modelo lineal:</p>
<pre class="r"><code>modelo_XMY &lt;- vglm(Indicador ~ Grupo + Si, family = cumulative(parallel = F ~ Grupo), data = mydata)
odds.ratios_XMY &lt;- exp(-cbind(coef(modelo_XMY), confint(modelo_XMY)))
summary_modelo_XMY &lt;- summary(modelo_XMY)@coef3
odds.ratios_XMY</code></pre>
<pre><code>##                                  2.5 %       97.5 %
## (Intercept):1 0.1015826325 0.412609003 0.0250092246
## (Intercept):2 0.0444277624 0.179293542 0.0110089078
## (Intercept):3 0.0078981658 0.036210022 0.0017227557
## (Intercept):4 0.0007460076 0.005143112 0.0001082083
## Grupo:1       0.6034088452 1.828980557 0.1990738682
## Grupo:2       0.7914697709 2.137970906 0.2929994961
## Grupo:3       0.7857085018 2.124413631 0.2905921148
## Grupo:4       0.2887330438 2.613733816 0.0318956621
## Si            1.2151276684 1.286966998 1.1472984563</code></pre>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> También ajustaremos otro modelo parcial logístico cumulativo regresando el indicador solamente en la intervención, aunque no es necesario para obtener los efectos naturales:</p>
<pre class="r"><code>modelo_XY &lt;- vglm(Indicador ~ Grupo, family = cumulative(parallel = F ~ Grupo, reverse = T), data = mydata)
odds.ratios_XY &lt;- exp(cbind(coef(modelo_XY), confint(modelo_XY)))
summary_modelo_XY &lt;- summary(modelo_XY)@coef3
odds.ratios_XY</code></pre>
<pre><code>##                              2.5 %     97.5 %
## (Intercept):1 5.5555556 2.73220728 11.2964334
## (Intercept):2 2.9333333 1.63253389  5.2706069
## (Intercept):3 0.9032258 0.54184524  1.5056271
## (Intercept):4 0.2040816 0.10338035  0.4028745
## Grupo:1       0.2652632 0.10590612  0.6644049
## Grupo:2       0.3557312 0.15685858  0.8067439
## Grupo:3       0.3795918 0.16531259  0.8716212
## Grupo:4       0.1065217 0.01311733  0.8650296</code></pre>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> A continuación se exponen brevemente las principales ideas subyacentes a cada método estadístico y se discuten los resultados obtenidos en acordancia.</p>
<p><br></p>
</div>
<div id="tests-de-equivalencia-superioridad-e-inferioridad" class="section level1">
<h1>Tests de equivalencia, superioridad e inferioridad</h1>
<p><br></p>
<blockquote>
<p>Without hoping to know whether each separate hypothesis is true or false, we may search for rules to govern our behaviour with regard to them, in following which we insure that, in the long run of experience, we shall not be too often wrong. - <span class="citation">Neyman and Pearson (1933)</span></p>
</blockquote>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> Este paradigma, que considera el investigador está interesado en seleccionar líneas de investigación que maximizan la calidad pragmática de su producción científica, ha sido recientemente reificado en forma de tests de equivalencia, superioridad e inferioridad <span class="citation">(Lakens 2017)</span>. Su característica principal consiste en la justificación del mínimo valor del parámetro por el que el investigador está interesado o dispuesto a invertir sus recursos y posteriormente verificar si un efecto, al menos tan importante como este, es experimentalmente detectado.<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a> En caso de optar por un test de equivalencia debemos establecer para <span class="math inline">\(\beta_{XY_j}\)</span>, por ejemplo, los mínimos efectos de interés <span class="math inline">\(\beta_{XY_j}\,_{min-}\)</span> y <span class="math inline">\(\beta_{XY_j}\,_{min+}\)</span><a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a> y luego diseñar un experimento que goce de la potencia estadística suficiente para detectar con alta probabilidad una desviación de ambos límites. Una vez desarrollado el experimento y computado el intervalo de confianza del parámetro, si observamos que ambos límites descansan en el intervalo de equivalencia definido por <span class="math inline">\(\beta_{XY_j}\,_{min-}\)</span> y <span class="math inline">\(\beta_{XY_j}\,_{min+}\)</span>, declaramos que <span class="math inline">\(\beta_{XY_j}\)</span> es equivalente a la hipótesis nula, o lo que es lo mismo, que su valor es demasiado pequeño para merecer el interés del investigador. Así, el científico adopta un enfoque conductual en el que su actividad investigadora se centra en detectar fenómenos que considera de práctica importancia, según sus recursos, mientras no erra más allá de un porcentaje de veces determinado por el error tipo I (<span class="math inline">\(\alpha\)</span>).</p>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> En el contexto de la intervención educativa que nos concierne, tan solo es necesario emplear tests de superioridad e inferioridad, estableciendo únicamente un mínimo efecto de interés para cada parámetro (<span class="math inline">\(\beta^\prime_{XY_j}\,_{min-}\)</span>, <span class="math inline">\(\beta_{XM}\,_{min-}\)</span> y <span class="math inline">\(\beta^\prime_{MY}\,_{min+}\)</span>), ya que no existe razón teórica alguna por la que pensar que la intervención educativa incremente las ilusiones causales o que exponerse a más administraciones del fármaco las disminuye. En los casos de <span class="math inline">\(\beta^\prime_{XY_j}\)</span> y <span class="math inline">\(\beta_{XM}\)</span> debemos observar si los límites inferiores de sus intervalos de confianza son mayores a <span class="math inline">\(\beta^\prime_{XY_j}\,_{min-}\)</span> y <span class="math inline">\(\beta_{XM}\,_{min-}\)</span>, respectivamente, para declarar superioridad e interpretar que la importancia práctica de los parámetros no compensa los recursos ni el interés que el investigador está dispuesto a invertir para estudiarlo. Respecto a <span class="math inline">\(\beta^\prime_{MY}\)</span>, debemos contrastar si el límite superior de su intervalo de confianza es menor a <span class="math inline">\(\beta^\prime_{MY}\,_{min+}\)</span> para declarar inferioridad y llegar a la misma conclusión.</p>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> La siguiente figura muestra las estimaciones de los parámetros en razón de momios (<em>odds ratios</em>) y sus intervalos de confianza al 95%. Si consideramos que <span class="math inline">\(\beta^\prime_{XY_j}\,_{min-} = \beta_{XM}\,_{min-} = 0.83\)</span>, es decir, que nuestro mínimo efecto de interés para los parámetros <span class="math inline">\(\beta^\prime_{XY_j}\)</span> y <span class="math inline">\(\beta_{XM}\)</span> es 0.83,<a href="#fn5" class="footnoteRef" id="fnref5"><sup>5</sup></a> hemos de rechazar que <span class="math inline">\(\beta_{XM}\)</span> sea superior al límite establecido ya que el límite superior de su intervalo de confianza es menor a tal magnitud. Por el contrario, no podemos tomar una decisión respecto a ninguna <span class="math inline">\(\beta^\prime_{XY_j}\)</span> debido a que sus intervalos de confianza no están ni exclusivamente contenidos en la región de superioridad ni bajo ella. Por tanto, los resultados de <span class="math inline">\(\beta^\prime_{XY_j}\)</span> se consideran inconclusos. Por último, si para el coeficiente <span class="math inline">\(\beta^\prime_{MY}\)</span> se ha establecido que <span class="math inline">\(\beta^\prime_{MY}\,_{min+} = 1.05\)</span>, es decir, que por cada decisión de no administrar el fármaco el mínimo efecto de interés equivale a un aumento del 5% en los momios del grupo de intervención de puntuar en una categoría inferior en comparación al de no intervención, nos encontramos en disposición de recharar la existencia de inferioridad.</p>
<pre class="r"><code>my.df &lt;- data.frame(x = c(0,1))
p &lt;- ggplot(my.df, aes(x = x))

plot5 &lt;- p + theme_gray() +
    scale_x_continuous(name = &quot;&quot;, seq(0, 1, 0.2)) +
    coord_cartesian(xlim = c(0, 1)) +
    scale_y_continuous(name = NULL, limits = c(0.5, 4.5), expand = c(0.03, 0), seq(1, 4, 1),
                       labels = c(TeX(&#39;$\\beta_{\\,XY_1}$&#39;), 
                                  TeX(&#39;$\\beta_{\\,XY_2}$&#39;), TeX(&#39;$\\beta_{\\,XY_3}$&#39;), 
                                  TeX(&#39;$\\beta_{\\,XY_4}$&#39;))) +
  theme(axis.text.x = element_text(size = 13), axis.title.x = element_text(size = 13),
        axis.text.y = element_text(size = 15, colour = &quot;black&quot;)) +
  theme(axis.title.x = element_text(margin = unit(c(5, 0, 0, 0), &quot;mm&quot;), colour=&quot;black&quot;)) +
    theme(axis.text.x = element_text(margin = unit(c(2, 0, 0, 0), &quot;mm&quot;), colour = &quot;black&quot;)) +
  theme(axis.text.y = element_text(margin = unit(c(0, 2, 0, 0), &quot;mm&quot;), colour = &quot;black&quot;)) +
    theme(axis.ticks.x = element_line(size = 0.4), 
          axis.ticks.y = element_line(size = 0.4)) +
    theme(panel.border = element_rect(fill = NA), axis.ticks.length = unit(0.2, &quot;cm&quot;),
          axis.line = element_line(size = 0.5, colour = &quot;black&quot;)) +
    theme(axis.ticks.length = unit(.15, &quot;cm&quot;)) +
    geom_segment(aes(x = odds.ratios_XY[5, 2], y = 1, xend = odds.ratios_XY[5, 3], yend = 1), linetype = &quot;solid&quot;, colour = &quot;black&quot;, lty = 2) +
    geom_segment(aes(x = odds.ratios_XY[6, 2], y = 2, xend = odds.ratios_XY[6, 3], yend = 2), linetype = &quot;solid&quot;, colour = &quot;black&quot;, lty = 2) +
    geom_segment(aes(x = odds.ratios_XY[7, 2], y = 3, xend = odds.ratios_XY[7, 3], yend = 3), linetype = &quot;solid&quot;, colour = &quot;black&quot;, lty = 2) +
    geom_segment(aes(x = odds.ratios_XY[8, 2], y = 4, xend = odds.ratios_XY[8, 3], yend = 4), linetype = &quot;solid&quot;, colour = &quot;black&quot;, lty = 2) +
    geom_segment(aes(x = 1/1.2, y = 0.5, xend = 1/1.2, yend = 4.5), colour = &quot;black&quot;, linetype = &quot;dashed&quot;, size = 0.3) +
    geom_point(aes(x = odds.ratios_XY[5, 1], y = 1), shape = 21, colour = &quot;black&quot;, fill = &quot;white&quot;, size = 4) +
    geom_point(aes(x = odds.ratios_XY[6, 1], y = 2), shape = 21, colour = &quot;black&quot;, fill = &quot;white&quot;, size = 4) +
    geom_point(aes(x = odds.ratios_XY[7, 1], y = 3), shape = 21, colour = &quot;black&quot;, fill = &quot;white&quot;, size = 4) +
    geom_point(aes(x = odds.ratios_XY[8, 1], y = 4), shape = 21, colour = &quot;black&quot;, fill = &quot;white&quot;, size = 4)

plot6 &lt;- p + theme_gray() +
  scale_x_continuous(name = &quot;&quot;, seq(0, 2.5, 0.5)) +
  coord_cartesian(xlim = c(0, 2.7)) +
  scale_y_continuous(name = NULL, limits = c(-0.5, 5.5), expand = c(0.03, 0), seq(0, 5, 1),
                     labels = c(TeX(&#39;$\\beta\\prime_{MY}$&#39;), TeX(&#39;$\\beta_{\\,XM}$&#39;), TeX(&#39;$\\beta\\prime_{XY_1}$&#39;), 
                                TeX(&#39;$\\beta\\prime_{XY_2}$&#39;), TeX(&#39;$\\beta\\prime_{XY_3}$&#39;), 
                                TeX(&#39;$\\beta\\prime_{XY_4}$&#39;))) +
  theme(axis.text.x = element_text(size = 13), axis.title.x = element_text(size = 13),
        axis.text.y = element_text(size = 15, colour = &quot;black&quot;)) +
  theme(axis.title.x = element_text(margin = unit(c(5, 0, 0, 0), &quot;mm&quot;), colour=&quot;black&quot;)) +
  theme(axis.text.x = element_text(margin = unit(c(2, 0, 0, 0), &quot;mm&quot;), colour = &quot;black&quot;)) +
  theme(axis.text.y = element_text(margin = unit(c(0, 2, 0, 0), &quot;mm&quot;), colour = &quot;black&quot;)) +
  theme(axis.ticks.x = element_line(size = 0.4), 
        axis.ticks.y = element_line(size = 0.4)) +
  theme(panel.border = element_rect(fill = NA), axis.ticks.length = unit(0.2, &quot;cm&quot;),
        axis.line = element_line(size = 0.5, colour = &quot;black&quot;)) +
  theme(axis.ticks.length = unit(.15, &quot;cm&quot;)) +
  geom_segment(aes(x = odds.ratios_XMY[5, 2], y = 5, xend = odds.ratios_XMY[5, 3], yend = 5), linetype = &quot;solid&quot;, colour = &quot;black&quot;, lty = 2) +
  geom_segment(aes(x = odds.ratios_XMY[6, 2], y = 4, xend = odds.ratios_XMY[6, 3], yend = 4), linetype = &quot;solid&quot;, colour = &quot;black&quot;, lty = 2) +
  geom_segment(aes(x = odds.ratios_XMY[7, 2], y = 3, xend = odds.ratios_XMY[7, 3], yend = 3), linetype = &quot;solid&quot;, colour = &quot;black&quot;, lty = 2) +
  geom_segment(aes(x = odds.ratios_XMY[8, 2], y = 2, xend = odds.ratios_XMY[8, 3], yend = 2), linetype = &quot;solid&quot;, colour = &quot;black&quot;, lty = 2) +
  geom_segment(aes(x = odds.ratios_XMY[9, 2], y = 0, xend = odds.ratios_XMY[9, 3], yend = 0), linetype = &quot;solid&quot;, colour = &quot;black&quot;, lty = 2) +
  geom_segment(aes(x = odds.ratios_XM[3, 2], y = 1, xend = odds.ratios_XM[3, 3], yend = 1), linetype = &quot;solid&quot;, colour = &quot;black&quot;, lty = 2) +
  geom_segment(aes(x = 1.05, y = -0.5, xend = 1.05, yend = 0.5), colour = &quot;black&quot;, linetype = &quot;dashed&quot;, size = 0.3) +    
  geom_segment(aes(x = 1/1.20, y = 0.5, xend = 1/1.20, yend = 5.5), colour = &quot;black&quot;, linetype = &quot;dashed&quot;, size = 0.3) +
  geom_point(aes(x = odds.ratios_XMY[5, 1], y = 5), shape = 21, colour = &quot;black&quot;, fill = &quot;white&quot;, size = 4) +
  geom_point(aes(x = odds.ratios_XMY[6, 1], y = 4), shape = 21, colour = &quot;black&quot;, fill = &quot;white&quot;, size = 4) +
  geom_point(aes(x = odds.ratios_XMY[7, 1], y = 3), shape = 21, colour = &quot;black&quot;, fill = &quot;white&quot;, size = 4) +
  geom_point(aes(x = odds.ratios_XMY[8, 1], y = 2), shape = 21, colour = &quot;black&quot;, fill = &quot;white&quot;, size = 4) +
  geom_point(aes(x = odds.ratios_XMY[9, 1], y = 0), shape = 21, colour = &quot;black&quot;, fill = &quot;white&quot;, size = 2) +
  geom_point(aes(x = odds.ratios_XM[3, 1], y = 1), shape = 21, colour = &quot;black&quot;, fill = &quot;white&quot;, size = 4)

grid.arrange(plot5, plot6, nrow = 1, bottom = textGrob(&quot;Razón de momios&quot;, vjust = -0.6, gp = gpar(fontsize = 14)))</code></pre>
<p><img src="TFG_files/figure-html/SESOI_2-1.png" width="960" style="display: block; margin: auto;" /></p>
<p><br></p>
</div>
<div id="estimacion-de-los-efectos-naturales-directos-indirectos-y-totales" class="section level1">
<h1>Estimación de los efectos naturales directos, indirectos y totales</h1>
<p><br></p>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> En general, los resultados sugerieren que existe un efecto total sobre la percepción de eficacia del fármaco atribuible a la intervención educativa <span class="math inline">\(X\)</span> y que es transmitido a <span class="math inline">\(Y\)</span> por medio de <span class="math inline">\(M\)</span>, tal y como hipotetizaron <span class="citation">Barberia (2018)</span>. Sin embargo, interpretar razones de momios puede resultar una tarea compleja. Las siguientes tablas muestran los efectos naturales directos, indirectos y totales, así como sus intervalos de confianza del 95%.</p>
<pre class="r"><code># Función para obtener las probabilidades predichas por nuestro modelo logístico cumulativo:
predictPO &lt;- function(Si, Grupo, Intercepto_1, Intercepto_2, Intercepto_3, Intercepto_4,
                      beta_X1, beta_X2, beta_X3, beta_X4, beta_M) {
  prob1 &lt;- 1 / (1 + exp(-Intercepto_1 + beta_X1* Grupo + beta_M * Si)) # Probabilidad de puntuar en la categoría 1, etc.
  prob2 &lt;- 1 / (1 + exp(-Intercepto_2 + beta_X2 * Grupo + beta_M * Si)) - prob1
  prob3 &lt;- 1 / (1 + exp(-Intercepto_3 + beta_X3 * Grupo + beta_M * Si)) - prob2 - prob1
  prob4 &lt;- 1 / (1 + exp(-Intercepto_4 + beta_X4 * Grupo + beta_M * Si)) - prob3 - prob2 - prob1
  prob5 &lt;- 1 - prob4 - prob3 - prob2 - prob1
  return(cbind(prob1, prob2, prob3, prob4, prob5))
}
# La idea para hallar los efectos contrafactuales es introducir en esta función los coeficientes estimados de ambos modelos.

simulaciones &lt;- 1e4 # Número de simulaciones
# Los resultados reportados en el manuscrito se realizaron con un millón de muestras pero es una exageración. Con tan solo 10000 se consigue una buena estimación.
n &lt;- nrow(mydata) # Número de observaciones del dataset.
# Creamos las matrices donde guardar los resultados:
NDE_matrix &lt;- matrix(NA, nrow = simulaciones, ncol = 5)
NIE_matrix &lt;- matrix(NA, nrow = simulaciones, ncol = 5)

set.seed(1)
for (i in 1:simulaciones) {
  # Modelo betabinomial:
  # Simulamos intercepto:
  Intercept &lt;- rnorm(1, summary_modelo_XM[1, &quot;Estimate&quot;], summary_modelo_XM[1, &quot;Std. Error&quot;])
  # Simulamos el efecto dela intervención educativa:
  Coefficient &lt;- rnorm(1, summary_modelo_XM[&quot;Grupo&quot;, &quot;Estimate&quot;], summary_modelo_XM[&quot;Grupo&quot;, &quot;Std. Error&quot;])
  # Probabilidad simulada de que un participante del grupo de intervención decida administrar el fármaco:
  prob1 &lt;- exp(Intercept + 1 * Coefficient) / (1 + exp(Intercept + 1 * Coefficient))
  # Probabilidad simulada de que un participante del grupo de no intervención decida administrar el fármaco:
  prob0 &lt;- exp(Intercept) / (1 + exp(Intercept))
  # Simulamos datos:
  M1 &lt;- rbetabinom(n, size = 40, prob1, rho = rho) # Número de administraciones del fármaco si los particpantes se expusieran a la intervención educativa.
  M0 &lt;- rbetabinom(n, size = 40, prob0, rho = rho) # Número de administraciones del fármaco si los particpantes no se expusieran a la intervención educativa.
  
  # Modelo cumulativo logístico parcial:
  # Simulamos interceptos:
  Intercepto_1 &lt;- rnorm(1, summary_modelo_XMY[1, &quot;Estimate&quot;], summary_modelo_XMY[1, &quot;Std. Error&quot;])
  Intercepto_2 &lt;- rnorm(1, summary_modelo_XMY[2, &quot;Estimate&quot;], summary_modelo_XMY[2, &quot;Std. Error&quot;])
  Intercepto_3 &lt;- rnorm(1, summary_modelo_XMY[3, &quot;Estimate&quot;], summary_modelo_XMY[3, &quot;Std. Error&quot;])
  Intercepto_4 &lt;- rnorm(1, summary_modelo_XMY[4, &quot;Estimate&quot;], summary_modelo_XMY[4, &quot;Std. Error&quot;])
  # Simulamos los efectos de la intervención educativa y el número de administraciones del fármaco en el indicador de la percepción de eficacia:
  beta_X1&lt;- rnorm(1, -summary_modelo_XMY[5, &quot;Estimate&quot;], summary_modelo_XMY[5, &quot;Std. Error&quot;])
  beta_X2 &lt;- rnorm(1, -summary_modelo_XMY[6, &quot;Estimate&quot;], summary_modelo_XMY[6, &quot;Std. Error&quot;])
  beta_X3 &lt;- rnorm(1, -summary_modelo_XMY[7, &quot;Estimate&quot;], summary_modelo_XMY[7, &quot;Std. Error&quot;])
  beta_X4 &lt;- rnorm(1, -summary_modelo_XMY[8, &quot;Estimate&quot;], summary_modelo_XMY[8, &quot;Std. Error&quot;])
  beta_M &lt;- rnorm(1, -summary_modelo_XMY[9, &quot;Estimate&quot;], summary_modelo_XMY[9, &quot;Std. Error&quot;])
  
  # Por último, predecimos las probabilidades de cada participante para puntuar en cada categoría:
  Y1M0 &lt;- predictPO(Si = M0, Grupo = 1,
                              Intercepto_1 = Intercepto_1, Intercepto_2 = Intercepto_2, Intercepto_3 = Intercepto_3,
                              Intercepto_4 = Intercepto_4, beta_X1= beta_X1, beta_X2 = beta_X2,
                              beta_X3 = beta_X3, beta_X4 = beta_X4, beta_M = beta_M)
  Y1M1 &lt;- predictPO(Si = M1, Grupo = 1,
                     Intercepto_1 = Intercepto_1, Intercepto_2 = Intercepto_2, Intercepto_3 = Intercepto_3,
                     Intercepto_4 = Intercepto_4, beta_X1= beta_X1, beta_X2 = beta_X2,
                     beta_X3 = beta_X3, beta_X4 = beta_X4, beta_M = beta_M)
  Y0M0 &lt;- predictPO(Si = M0, Grupo = 0,
                                       Intercepto_1 = Intercepto_1, Intercepto_2 = Intercepto_2, Intercepto_3 = Intercepto_3,
                                       Intercepto_4 = Intercepto_4, beta_X1= beta_X1, beta_X2 = beta_X2,
                                       beta_X3 = beta_X3, beta_X4 = beta_X4, beta_M = beta_M)
  Y0M1 &lt;- predictPO(Si = M1, Grupo = 0,
                              Intercepto_1 = Intercepto_1, Intercepto_2 = Intercepto_2, Intercepto_3 = Intercepto_3,
                              Intercepto_4 = Intercepto_4, beta_X1= beta_X1, beta_X2 = beta_X2,
                              beta_X3 = beta_X3, beta_X4 = beta_X4, beta_M = beta_M)
  # Estimamos los efectos:
  NDE &lt;- Y1M0 - Y0M0 # Efecto natural directo
  NIE &lt;- Y0M1 - Y0M0 # Efecto natural indirecto
  NDE_matrix[i, ] &lt;- apply(NDE, MARGIN = 2, mean) # NDE promediado para cada categoría.
  NIE_matrix[i, ] &lt;- apply(NIE, MARGIN = 2, mean) # NIE promediado para cada categoría.
  # Repetimos esta simulación muchas veces.
}
NDE_estimate &lt;- apply(NDE_matrix, MARGIN = 2, mean) # Media de los NDE promediados para cada categoría.
NIE_estimate &lt;- apply(NIE_matrix, MARGIN = 2, mean) # Media de los NIE promediados para cada categoría.
TE_estimate &lt;- NDE_estimate + NIE_estimate # Efecto total

# Hallamos los intervalos de confianza del 95% buscando los cuantiles 0.025 y 0.975 de la distribución de los efectos:
confint_NDE_estimate &lt;- apply(NDE_matrix, MARGIN = 2, function(x) quantile(x, probs = c(0.025, 0.975)))
confint_NIE_estimate &lt;- apply(NIE_matrix, MARGIN = 2,  function(x) quantile(x, probs = c(0.025, 0.975)))
confint_TE_estimate &lt;- apply(NDE_matrix + NIE_matrix, MARGIN = 2,  function(x) quantile(x, probs = c(0.025, 0.975)))
NDEs &lt;- cbind(confint_NDE_estimate[1, ], NDE_estimate, confint_NDE_estimate[2, ])
NIEs &lt;- cbind(confint_NIE_estimate[1, ], NIE_estimate, confint_NIE_estimate[2, ])
TEs &lt;- cbind(confint_TE_estimate[1, ], TE_estimate, confint_TE_estimate[2, ])
rownames(NDEs) &lt;- rownames(NIEs) &lt;- rownames(TEs) &lt;- paste(&quot;Categoría&quot;, seq(1:5), sep = &quot; &quot;)
colnames(NDEs) &lt;- colnames(NIEs) &lt;- colnames(TEs) &lt;- c(&quot;2.5%&quot;, &quot;Estimación&quot;, &quot;97.5%&quot;)

kable(NDEs, digits = 3, caption = &quot;Efecto Natural Directo&quot;, align = &quot;c&quot;) %&gt;%
  kable_styling(bootstrap_options = &quot;striped&quot;, full_width = F)
kable(NIEs, digits = 3, caption = &quot;Efecto Natural Indirecto&quot;, align = &quot;c&quot;) %&gt;%
  kable_styling(bootstrap_options = &quot;striped&quot;, full_width = F)
kable(TEs, digits = 3, caption = &quot;Efecto Total&quot;, align = &quot;c&quot;) %&gt;%
  kable_styling(bootstrap_options = &quot;striped&quot;, full_width = F)</code></pre>
<table class="table table-striped" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
Efecto Natural Directo
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:center;">
2.5%
</th>
<th style="text-align:center;">
Estimación
</th>
<th style="text-align:center;">
97.5%
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Categoría 1
</td>
<td style="text-align:center;">
-0.051
</td>
<td style="text-align:center;">
0.056
</td>
<td style="text-align:center;">
0.211
</td>
</tr>
<tr>
<td style="text-align:left;">
Categoría 2
</td>
<td style="text-align:center;">
-0.217
</td>
<td style="text-align:center;">
-0.025
</td>
<td style="text-align:center;">
0.151
</td>
</tr>
<tr>
<td style="text-align:left;">
Categoría 3
</td>
<td style="text-align:center;">
-0.191
</td>
<td style="text-align:center;">
0.003
</td>
<td style="text-align:center;">
0.188
</td>
</tr>
<tr>
<td style="text-align:left;">
Categoría 4
</td>
<td style="text-align:center;">
-0.183
</td>
<td style="text-align:center;">
0.049
</td>
<td style="text-align:center;">
0.305
</td>
</tr>
<tr>
<td style="text-align:left;">
Categoría 5
</td>
<td style="text-align:center;">
-0.299
</td>
<td style="text-align:center;">
-0.084
</td>
<td style="text-align:center;">
0.115
</td>
</tr>
</tbody>
</table>
<table class="table table-striped" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
Efecto Natural Indirecto
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:center;">
2.5%
</th>
<th style="text-align:center;">
Estimación
</th>
<th style="text-align:center;">
97.5%
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Categoría 1
</td>
<td style="text-align:center;">
0.056
</td>
<td style="text-align:center;">
0.184
</td>
<td style="text-align:center;">
0.330
</td>
</tr>
<tr>
<td style="text-align:left;">
Categoría 2
</td>
<td style="text-align:center;">
-0.049
</td>
<td style="text-align:center;">
0.029
</td>
<td style="text-align:center;">
0.129
</td>
</tr>
<tr>
<td style="text-align:left;">
Categoría 3
</td>
<td style="text-align:center;">
-0.125
</td>
<td style="text-align:center;">
-0.003
</td>
<td style="text-align:center;">
0.100
</td>
</tr>
<tr>
<td style="text-align:left;">
Categoría 4
</td>
<td style="text-align:center;">
-0.246
</td>
<td style="text-align:center;">
-0.099
</td>
<td style="text-align:center;">
0.015
</td>
</tr>
<tr>
<td style="text-align:left;">
Categoría 5
</td>
<td style="text-align:center;">
-0.289
</td>
<td style="text-align:center;">
-0.112
</td>
<td style="text-align:center;">
-0.009
</td>
</tr>
</tbody>
</table>
<table class="table table-striped" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
Efecto Total
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:center;">
2.5%
</th>
<th style="text-align:center;">
Estimación
</th>
<th style="text-align:center;">
97.5%
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Categoría 1
</td>
<td style="text-align:center;">
0.065
</td>
<td style="text-align:center;">
0.240
</td>
<td style="text-align:center;">
0.456
</td>
</tr>
<tr>
<td style="text-align:left;">
Categoría 2
</td>
<td style="text-align:center;">
-0.214
</td>
<td style="text-align:center;">
0.005
</td>
<td style="text-align:center;">
0.207
</td>
</tr>
<tr>
<td style="text-align:left;">
Categoría 3
</td>
<td style="text-align:center;">
-0.238
</td>
<td style="text-align:center;">
0.000
</td>
<td style="text-align:center;">
0.210
</td>
</tr>
<tr>
<td style="text-align:left;">
Categoría 4
</td>
<td style="text-align:center;">
-0.334
</td>
<td style="text-align:center;">
-0.050
</td>
<td style="text-align:center;">
0.278
</td>
</tr>
<tr>
<td style="text-align:left;">
Categoría 5
</td>
<td style="text-align:center;">
-0.540
</td>
<td style="text-align:center;">
-0.196
</td>
<td style="text-align:center;">
0.014
</td>
</tr>
</tbody>
</table>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> El <span class="math inline">\(NDE\)</span> en la categoría 1 es interpretado de la siguiente manera: se estima que, si los participantes del experimento hubieran sido expuestos a la intervención pero se eliminara su efecto sobre la decisión de administrar el fármaco, existiría un 5.6% más de probabilidades de puntuar en esa categoría respecto a no pasar por la intervención. El intervalo de confianza <span class="math inline">\((-5.1\%, \, 21.1\%)\)</span> contiene el verdadero valor con un 95% de probabilidad. Por otro lado, para la misma categoría, el <span class="math inline">\(NIE\)</span> es interpretado de la siguiente manera: si ningún participante fuera expuesto a la intervención pero decidieran administrar el fármaco como si hubieran pasado por ella, habría un incremento del 18.4% en las probabilidades de puntuar en esa categoría respecto a la situación en la que administrasen el fármaco como si no hubieran pasado por la intervención.</p>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> Aquí podríamos haber establecido el mínimo efecto de interés, en lugar de en los parámetros, ya que estos resultados son más intuitivos que las razones de momios.</p>
<p><br></p>
</div>
<div id="test-de-rigor" class="section level1">
<h1>Test de rigor</h1>
<p><br></p>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> Esta perspectiva engloba una filosofía madura que reúne los mejores aspectos de las concepciones de Fisher y Neyman<a href="#fn6" class="footnoteRef" id="fnref6"><sup>6</sup></a> <span class="citation">(Mayo and Spanos 2006, <span class="citation">Mayo and Spanos (2011)</span>)</span>. A diferencia de la visión conductual anterior, se considera que calibrar el porcentage de veces que uno realiza inferencias incorrectas no es suficiente. También es necesario poner de relieve el rigor (<em>severity</em>) con el que se sostienen hipotéticas inferencias sobre el valor del parámetro. Esta idea se ilustra en un principio fundamental:</p>
<p><strong>Principio de rigor</strong>: Si una hipótesis pasa un test que posee una alta probabilidad de detectar una incompatibilidad con ella, entonces existe evidencia a favor de dicha hipótesis. Por el contrario, si los datos obtenidos concuerdan con la hipótesis pero, aún siendo verdadera, el test es incapaz de detectar una incompatibilidad con alta probabilidad, entonces no existe suficiente evidencia a favor de la misma.</p>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> En un contexto estadístico podríamos traducirlo de la siguiente manera: la estimación de un parámetro representa buena evidencia a favor de una hipótesis si, en primer lugar, es compatible con ella y, en segundo lugar, de ser falsa el test habría revelado con alta probabilidad un valor menos compatible. Los p-valores e intervalos de confianza pueden aportar información del rigor de una inferencia particular. Si un test es diseñado para poseer una considerable potencia estadística para detectar <span class="math inline">\(\theta_0\)</span>, se observa un resultado positivo y el límite inferior del intervalo de confianza lo excluye, esta incompatibilidad puede considerarse como buena evidencia de que el valor del parámetro es superior a <span class="math inline">\(\theta_0\)</span> porque, de lo contrario, se habría observado una menor estimación con alta probabilidad. Es decir, <span class="math inline">\(\theta &gt; \theta_0\)</span> es una inferencia que pasa el test con suficiente rigor.</p>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> Sin embargo, la información procedente de un p-valor o un intervalo de confianza es limitada porque no aporta el grado de rigor con el que todos los posibles valores del parámetro han pasado o no el test. El p-valor solo comunica la discrepancia del estadístico respecto a la hipótesis nula mientras que los valores contenidos en los intervalo de confianza meramente son aquellos ante los que no se habría rechazado la hipótesis nula si esta se correspondiera con el valor del parámetro observado.<a href="#fn7" class="footnoteRef" id="fnref7"><sup>7</sup></a> Sin embargo, una medida más informativa del rigor aplicable a cada posible valor que puede tomar el parámetro puede computarse a posteriori (tras obtener los datos). Se trata de la probabilidad de haber observado una diferencia mayor o menor que la obtenida considerando cada uno de los posibles valores que puede tomar el parámetro. Esto es equivalente a realizar un análisis de potencia estadística tomando el estadístico observado, y no el valor de la hipótesis nula, como punto de referencia.</p>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> En la sección anterior habíamos visto que las <span class="math inline">\(\beta_{XY_j}\)</span>, <span class="math inline">\(\beta_{XM}\)</span> y <span class="math inline">\(\beta^\prime_{MY}\)</span> son significativas ya que los límites de los intervalos de confianza excluyen el 1 aportando evidencia de una discrepancia de la hipótesis nula. En esta situación, en lugar de limitarse a establecer o no la superioridad, inferioridad o inconclusibilidad de las estimaciones respecto a un mínimo efecto de interés, conviene establecer la máxima o mínima discrepancia que estamos en situación de inferir con rigor. Para ello, dado que los parámetros de la regresión betabinomial y ordinal logística siguen una distribución gausiana, debemos computar la probabilidad cumulativa</p>
<p><span class="math display">\[\frac{1}{\hat{\sigma}_{\beta} \sqrt {2\pi } } ~~ \int_{\infty}^{\beta} \text{exp}{~ - \frac{ ( {\hat{\beta} - \beta } )^2 }{2\hat{\sigma}_{\beta}^2} } \, d\beta\]</span></p>
<p>para cada posible valor que pueda tomar <span class="math inline">\(\beta\)</span>.<a href="#fn8" class="footnoteRef" id="fnref8"><sup>8</sup></a></p>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> Por el contrario, una vez incluimos el mediador en la regresión, las <span class="math inline">\(\beta^\prime_{XY_j}\)</span> dejan de ser significativamente distintas de 1. En este otro caso, empleamos la función cumulativa complementaria ya que conviene establecer la máxima discrepancia que podemos descartar con rigor:</p>
<p><span class="math display">\[\frac{1}{\hat{\sigma}_{\beta^\prime_{XY_j}} \sqrt {2\pi } } ~~ \int_{\beta^\prime_{XY_j}}^{\infty} \text{exp}{~ - \frac{ \left( {\hat{\beta^\prime}_{XY_j} - \beta^\prime_{XY_j} } \right)^2 }{2\hat{\sigma}_{\beta^\prime_{XY_j}}^2} } \, d\beta^\prime_{XY_j}\]</span></p>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> Volviendo al experimento que nos concierne y siguiendo el método mencionado, la siguiente figura muestra el rigor con el que distintas inferencias sobre los parámetros, estimados en razón de momios, pasan o no el test.</p>
<pre class="r"><code>my.df &lt;- data.frame(x = c(0,1))
p &lt;- ggplot(my.df, aes(x=x))
plot7 &lt;- p + theme_gray() +
    theme(plot.margin = margin(0.5, 1, 0.2, 0.5, &#39;cm&#39;)) +
    scale_x_continuous(name = &quot;Razón de momios&quot;, limits = c(0, 1), seq(0, 1, 0.1)) +
    scale_y_continuous(name = &quot;Rigor&quot;, expand = c(0.03, 0), seq(0, 1, 0.1)) +
    theme(axis.text.x = element_text(size = 12), axis.title.x = element_text(size = 14),
          axis.text.y = element_text(size = 12), axis.title.y = element_text(size = 14)) +
    theme(axis.text.x = element_text(margin = unit(c(3, 0, 0, 0), &quot;mm&quot;), colour = &quot;black&quot;),
          axis.text.y = element_text(margin = unit(c(0, 3, 0, 0), &quot;mm&quot;), colour = &quot;black&quot;)) +
    theme(axis.title.x = element_text(margin = unit(c(5, 0, 0, 0), &quot;mm&quot;), colour = &quot;black&quot;),
          axis.title.y = element_text(margin = unit(c(0, 5, 0, 0), &quot;mm&quot;), colour = &quot;black&quot;)) +
    theme(axis.ticks.x = element_line(size = 0.6), 
          axis.ticks.y = element_line(size = 0.6)) +
    theme(panel.border = element_rect(fill = NA), axis.ticks.length = unit(0.2, &quot;cm&quot;)) +
    theme(legend.position = c(0.85, 0.25))  +
    stat_function(fun = function(x, i, sd) 1 - pnorm(i, log(x), sd), n = 1e3,
                  args = list(i = summary_modelo_XY[&quot;Grupo:1&quot;, &quot;Estimate&quot;], sd = summary_modelo_XY[&quot;Grupo:1&quot;, &quot;Std. Error&quot;]), 
                  lwd = 2, colour = &quot;#848484&quot;) +
    stat_function(fun = function(x, i, sd) 1 - pnorm(i, log(x), sd), n = 1e3,
                  args = list(i = summary_modelo_XY[&quot;Grupo:2&quot;, &quot;Estimate&quot;], sd = summary_modelo_XY[&quot;Grupo:2&quot;, &quot;Std. Error&quot;]), 
                  lwd = 2, colour = &quot;#6582F3&quot;) +
    stat_function(fun = function(x, i, sd) 1 - pnorm(i, log(x), sd), n = 1e3,
                  args = list(i = summary_modelo_XY[&quot;Grupo:3&quot;, &quot;Estimate&quot;], sd = summary_modelo_XY[&quot;Grupo:3&quot;, &quot;Std. Error&quot;]), 
                  lwd = 2, colour = &quot;#ECAC09&quot;) +
    stat_function(fun = function(x, i, sd) 1 - pnorm(i, log(x), sd), n = 1e3,
                  args = list(i = summary_modelo_XY[&quot;Grupo:4&quot;, &quot;Estimate&quot;], sd = summary_modelo_XY[&quot;Grupo:4&quot;, &quot;Std. Error&quot;]), 
                  lwd = 2, colour = &quot;#E13B32&quot;) +
    stat_function(fun = function(x, i, sd) 1 - pnorm(i, log(x), sd), n = 1e3,
                  args = list(i = summary_modelo_XM[&quot;Grupo&quot;, &quot;Estimate&quot;], sd = summary_modelo_XM[&quot;Grupo&quot;, &quot;Std. Error&quot;]), 
                  lwd = 2, colour = &quot;black&quot;) +
    annotate(&quot;text&quot;, x = 0.75, y = 0.6, label = TeX(&#39;$\\beta_{\\,XY_1}$&#39;), colour=&quot;black&quot;, size = 5) +
    annotate(&quot;text&quot;, x = 0.75, y = 0.52, label = TeX(&#39;$\\beta_{\\,XY_2}$&#39;), colour=&quot;black&quot;, size = 5) +
    annotate(&quot;text&quot;, x = 0.75, y = 0.44, label = TeX(&#39;$\\beta_{\\,XY_3}$&#39;), parse=T, colour = &quot;black&quot;, size = 5) +
    annotate(&quot;text&quot;, x = 0.75, y = 0.36, label = TeX(&#39;$\\beta_{\\,XY_4}$&#39;), parse=T, colour = &quot;black&quot;, size = 5) +
    annotate(&quot;text&quot;, x = 0.75, y = 0.28, label = TeX(&#39;$\\beta_{\\,XM}$&#39;), parse=T, colour = &quot;black&quot;, size = 5) +
    geom_rect(xmin = 0.85, xmax = 0.91,   ymin = 0.63, ymax = 0.57,   fill = &quot;#848484&quot;) +
    geom_rect(xmin = 0.85, xmax = 0.91,   ymin = 0.55, ymax = 0.49,   fill = &quot;#6582F3&quot;) +
    geom_rect(xmin = 0.85, xmax = 0.91,   ymin = 0.47, ymax = 0.41,   fill = &quot;#ECAC09&quot;) +
    geom_rect(xmin = 0.85, xmax = 0.91,   ymin = 0.39, ymax = 0.33,   fill = &quot;#E13B32&quot;) +
    geom_rect(xmin = 0.85, xmax = 0.91,   ymin = 0.31, ymax = 0.25,   fill = &quot;black&quot;)

plot8 &lt;- p + theme_gray() +
  theme(plot.margin = margin(0.5, 1, 0.2, 0.5, &#39;cm&#39;)) +
  scale_x_continuous(name = &quot;Razón de momios&quot;, limits = c(0, 2), seq(0, 2, 0.2)) +
  scale_y_continuous(name = &quot;Rigor&quot;, expand = c(0.03, 0), seq(0, 1, 0.1)) +
  theme(axis.text.x = element_text(size = 12), axis.title.x = element_text(size = 14),
        axis.text.y = element_text(size = 12), axis.title.y = element_text(size = 14)) +
  theme(axis.text.x = element_text(margin = unit(c(3, 0, 0, 0), &quot;mm&quot;), colour = &quot;black&quot;),
        axis.text.y = element_text(margin = unit(c(0, 3, 0, 0), &quot;mm&quot;), colour = &quot;black&quot;)) +
  theme(axis.title.x = element_text(margin = unit(c(5, 0, 0, 0), &quot;mm&quot;), colour = &quot;black&quot;),
        axis.title.y = element_text(margin = unit(c(0, 5, 0, 0), &quot;mm&quot;), colour = &quot;black&quot;)) +
  theme(axis.ticks.x = element_line(size = 0.6), 
        axis.ticks.y = element_line(size = 0.6)) +
  theme(panel.border = element_rect(fill = NA), axis.ticks.length = unit(0.2, &quot;cm&quot;)) +
  theme(legend.position = c(0.85, 0.25))  +
  stat_function(fun = function(x, i, sd) pnorm(i, log(x), sd), n = 1e3,
                args = list(i = -summary_modelo_XMY[&quot;Grupo:1&quot;, &quot;Estimate&quot;], sd = summary_modelo_XMY[&quot;Grupo:1&quot;, &quot;Std. Error&quot;]), 
                lwd = 2, colour = &quot;#848484&quot;) +
  stat_function(fun = function(x, i, sd) pnorm(i, log(x), sd), n = 1e3,
                args = list(i = -summary_modelo_XMY[&quot;Grupo:2&quot;, &quot;Estimate&quot;], sd = summary_modelo_XMY[&quot;Grupo:2&quot;, &quot;Std. Error&quot;]), 
                lwd = 2, colour = &quot;#6582F3&quot;) +
  stat_function(fun = function(x, i, sd) pnorm(i, log(x), sd), n = 1e3,
                args = list(i = -summary_modelo_XMY[&quot;Grupo:3&quot;, &quot;Estimate&quot;], sd = summary_modelo_XMY[&quot;Grupo:3&quot;, &quot;Std. Error&quot;]), 
                lwd = 2, colour = &quot;#ECAC09&quot;) +
  stat_function(fun = function(x, i, sd) pnorm(i, log(x), sd), n = 1e3,
                args = list(i = -summary_modelo_XMY[&quot;Grupo:4&quot;, &quot;Estimate&quot;], sd = summary_modelo_XMY[&quot;Grupo:4&quot;, &quot;Std. Error&quot;]), 
                lwd = 2, colour = &quot;#E13B32&quot;) +
  annotate(&quot;text&quot;, x = 1.5, y = 0.6, label = TeX(&#39;$\\beta\\prime_{XY_1}$&#39;), colour=&quot;black&quot;, size = 5) +
  annotate(&quot;text&quot;, x = 1.5, y = 0.52, label = TeX(&#39;$\\beta\\prime_{XY_2}$&#39;), colour=&quot;black&quot;, size = 5) +
  annotate(&quot;text&quot;, x = 1.5, y = 0.44, label = TeX(&#39;$\\beta\\prime_{XY_3}$&#39;), parse=T, colour = &quot;black&quot;, 
           size = 5) +
  annotate(&quot;text&quot;, x = 1.5, y = 0.36, label = TeX(&#39;$\\beta\\prime_{XY_4}$&#39;), parse=T, colour = &quot;black&quot;, 
           size = 5) +
  geom_rect(xmin = 1.7, xmax = 1.82,   ymin = 0.63, ymax = 0.57,   fill = &quot;#848484&quot;) +
  geom_rect(xmin = 1.7, xmax = 1.82,   ymin = 0.55, ymax = 0.49,   fill = &quot;#6582F3&quot;) +
  geom_rect(xmin = 1.7, xmax = 1.82,   ymin = 0.47, ymax = 0.41,   fill = &quot;#ECAC09&quot;) +
  geom_rect(xmin = 1.7, xmax = 1.82,   ymin = 0.39, ymax = 0.33,   fill = &quot;#E13B32&quot;)

plot9 &lt;- p + theme_gray() +
  theme(plot.margin = margin(0.5, 1, 0.2, 0.5, &#39;cm&#39;)) +
  scale_x_continuous(name = &quot;Razón de momios&quot;, limits = c(1.1, 1.3), seq(1.1, 1.3, 0.05)) +
  scale_y_continuous(name = &quot;Rigor&quot;, expand = c(0.03, 0), seq(0, 1, 0.1)) +
  theme(axis.text.x = element_text(size = 12), axis.title.x = element_text(size = 14),
        axis.text.y = element_text(size = 12), axis.title.y = element_text(size = 14)) +
  theme(axis.text.x = element_text(margin = unit(c(3, 0, 0, 0), &quot;mm&quot;), colour = &quot;black&quot;),
        axis.text.y = element_text(margin = unit(c(0, 3, 0, 0), &quot;mm&quot;), colour = &quot;black&quot;)) +
  theme(axis.title.x = element_text(margin = unit(c(5, 0, 0, 0), &quot;mm&quot;), colour = &quot;black&quot;),
        axis.title.y = element_text(margin = unit(c(0, 5, 0, 0), &quot;mm&quot;), colour = &quot;black&quot;)) +
  theme(axis.ticks.x = element_line(size = 0.6), 
        axis.ticks.y = element_line(size = 0.6)) +
  theme(panel.border = element_rect(fill = NA), axis.ticks.length = unit(0.2, &quot;cm&quot;)) +
  theme(legend.position = c(0.85, 0.25)) +
  stat_function(fun = function(x, i, sd) pnorm(i, log(x), sd), n = 1e3,
                args = list(i = -summary_modelo_XMY[&quot;Si&quot;, &quot;Estimate&quot;], sd = summary_modelo_XMY[&quot;Si&quot;, &quot;Std. Error&quot;]), 
                lwd = 2, colour = &quot;#d162d6&quot;) +
  annotate(&quot;text&quot;, x = 1.25, y = 0.4, label = TeX(&#39;$\\beta\\prime_{MY}$&#39;), colour=&quot;black&quot;, size = 5) +
  geom_rect(xmin = 1.268, xmax = 1.28,   ymin = 0.43, ymax = 0.37,   fill = &quot;#d162d6&quot;) +
  geom_segment(aes(x = odds.ratios_XMY[9, 2], y = 0.5, xend = odds.ratios_XMY[9, 3], yend = 0.5), linetype = &quot;solid&quot;, colour = &quot;black&quot;,
               lty = 2) +
  geom_point(aes(x = odds.ratios_XMY[9, 1], y = 0.5), shape = 21, colour = &quot;black&quot;, fill = &quot;white&quot;, size = 4)

plot7 + plot8 + plot9 + plot_layout(nrow = 2, widths = c(2, 2, 1))
</code></pre>
<p><img src="TFG_files/figure-html/Severity_2-1.png" width="960" style="display: block; margin: auto;" /></p>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> El parámetro <span class="math inline">\(\beta^\prime_{MY}\)</span> es interpretado como sigue: si su valor real fuera, aproximadamente, 1.15, entonces se habría obtenido con un 97.5% de probabilidad un efecto menor al estimado (<span class="math inline">\(\simeq{1.21}\)</span>). Por tanto, la inferencia <span class="math inline">\(\beta^\prime_{MY} &gt; 1.15\)</span> pasa el test con alto rigor. Igualmente, si el valor real del parámetro <span class="math inline">\(\beta^\prime_{XY_1}\)</span> fuera 0.2, entonces se habría observado, con un 97.5% de probabilidad, un efecto mayor al obtenido (<span class="math inline">\(\simeq{0.6}\)</span>). Por tanto, podemos inferir con gran rigor que <span class="math inline">\(\beta^\prime_{XY_1} &gt; 0.2\)</span>.<a href="#fn9" class="footnoteRef" id="fnref9"><sup>9</sup></a> Siguiendo el mismo principio, podemos estimar los NDE, NIE y TE de cada categoría que estamos en disposición de inferir con rigor. Para ello computamos tales efectos usando un valor de los parámetros para los que se cuente con suficiente evidencia. En el caso de <span class="math inline">\(\beta^\prime_{MY}\)</span> hemos constatado buena evidencia que es superior a 1.15. En cuanto a <span class="math inline">\(\beta_{XM}\)</span>, podemos garantizar con otro 97.5% de rigor que la razón de momios es inferior a 0.662. Respecto a las <span class="math inline">\(\beta^\prime_{MY}\)</span>, no podemos inferir con rigor que desempeñen algún efecto por lo que las ponemos a 0. De esta manera, el NDE es 0 y el NIE es similar al efecto total (TE). Tras realizar las simulaciones para estimar las condiciones contrafactuales, los resultados indican que el máximo efecto que podemos inferir con más que razonable evidencia es un aumento de, al menos, un 9.9% de probabilidades de puntuar en la primera categoría en detrimento de las categorías 3, 4 y 5.</p>
<pre class="r"><code>  Intercept &lt;- summary_modelo_XM[1, &quot;Estimate&quot;]
  Coefficient &lt;- summary_modelo_XM[&quot;Grupo&quot;, &quot;Estimate&quot;] + summary_modelo_XM[&quot;Grupo&quot;, &quot;Std. Error&quot;] * qnorm(0.975)
  prob1 &lt;- exp(Intercept + 1 * Coefficient) / (1 + exp(Intercept + 1 * Coefficient))
  prob0 &lt;- exp(Intercept) / (1 + exp(Intercept))
  
  Intercepto_1 &lt;- summary_modelo_XMY[1, &quot;Estimate&quot;]
  Intercepto_2 &lt;- summary_modelo_XMY[2, &quot;Estimate&quot;]
  Intercepto_3 &lt;- summary_modelo_XMY[3, &quot;Estimate&quot;]
  Intercepto_4 &lt;- summary_modelo_XMY[4, &quot;Estimate&quot;]
  beta_X1 &lt;- 0
  beta_X2 &lt;- 0
  beta_X3 &lt;- 0
  beta_X4 &lt;- 0
  beta_M &lt;- -summary_modelo_XMY[9, &quot;Estimate&quot;] + summary_modelo_XMY[9, &quot;Std. Error&quot;] * qnorm(0.025)
  
set.seed(1)
for (i in 1:simulaciones) {
  M1 &lt;- rbetabinom(n, size = 40, prob1, rho = rho)
  M0 &lt;- rbetabinom(n, size = 40, prob0, rho = rho)
  
  Y0M0 &lt;- predictPO(Si = M0, Grupo = 0,
                                       Intercepto_1 = Intercepto_1, Intercepto_2 = Intercepto_2, Intercepto_3 = Intercepto_3,
                                       Intercepto_4 = Intercepto_4, beta_X1= beta_X1, beta_X2 = beta_X2,
                                       beta_X3 = beta_X3, beta_X4 = beta_X4, beta_M = beta_M)
  Y0M1 &lt;- predictPO(Si = M1, Grupo = 0,
                              Intercepto_1 = Intercepto_1, Intercepto_2 = Intercepto_2, Intercepto_3 = Intercepto_3,
                              Intercepto_4 = Intercepto_4, beta_X1= beta_X1, beta_X2 = beta_X2,
                              beta_X3 = beta_X3, beta_X4 = beta_X4, beta_M = beta_M)
  NIE &lt;- Y0M1 - Y0M0 # Natural indirect effect
  NIE_matrix[i, ] &lt;- apply(NIE, MARGIN = 2, mean)
}
Severe_NIE &lt;- apply(NIE_matrix, MARGIN = 2, mean)
Severe_NIE &lt;- as.data.frame(Severe_NIE)
rownames(Severe_NIE) &lt;- c(paste(&quot;Categoría&quot;, 1:5, sep = &quot; &quot;))
colnames(Severe_NIE) &lt;- &quot;Máximo NIE con alto rigor&quot;

kable(Severe_NIE, digits = 3, align = &quot;c&quot;) %&gt;%
  kable_styling(bootstrap_options = &quot;striped&quot;, full_width = F)</code></pre>
<table class="table table-striped" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:center;">
Máximo NIE con alto rigor
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Categoría 1
</td>
<td style="text-align:center;">
0.099
</td>
</tr>
<tr>
<td style="text-align:left;">
Categoría 2
</td>
<td style="text-align:center;">
0.008
</td>
</tr>
<tr>
<td style="text-align:left;">
Categoría 3
</td>
<td style="text-align:center;">
-0.034
</td>
</tr>
<tr>
<td style="text-align:left;">
Categoría 4
</td>
<td style="text-align:center;">
-0.059
</td>
</tr>
<tr>
<td style="text-align:left;">
Categoría 5
</td>
<td style="text-align:center;">
-0.014
</td>
</tr>
</tbody>
</table>
<p>Con la finalidad de familiarizar al lector con esta manera de interpretar la evidencia estadística se ha desarrollado una app, disponible en la plataforma Shiny , que permite obtener curvas de rigor para análisis simples: <a href="https://marcosjnez.shinyapps.io/Severity/">Severity</a>. La notación empleada en esta app emula la utilizada por <span class="citation">Mayo and Spanos (2011)</span>.</p>
<p><br></p>
</div>
<div id="factor-de-bayes" class="section level1">
<h1>Factor de Bayes</h1>
<p><br></p>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> Con el desarrollo de procesadores más potentes y sofisticado <em>software</em> los métodos bayesianos han ido adquiriendo creciente popularidad. Sin embargo, las diferencias que los separan de los tradicionales no son nimios sino que trascienden hasta el mismo concepto de probabilidad. Este término ya no es interpretado como la frecuencia de un evento en un proceso aleatorio sino que atañe una noción personal y subjetiva. Esta nueva noción está presente en el Teorema de Bayes como una distribución a priori <span class="math inline">\(p(\theta)\)</span> que representa la verosimilitud subjetiva de cada posible valor del parámetro antes de observar los datos.</p>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> Teorema de Bayes:</p>
<p><span class="math display">\[ p(\theta\, | \,y) = \frac{p(y\, | \,\theta)}{p(y)} \,p(\theta) \]</span></p>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> Consecuentemente, el término evidencia también es reconceptualizado pues ya no se pretende evaluar el grado de rigor con el que distintas afirmaciones sobre el valor del parámetro pasan el test sino conocer su distribución probabilística. Particularmente, el enfoque adoptado en esta sección considera que algo se corresponde con evidencia cuando provoca un cambio en la creencia que una persona mantiene respecto a una hipótesis <span class="citation">(Morey, Romeijn, and Rouder 2016)</span>. Reordenando el Teorema de Bayes, podemos comprobar que dicho cambio viene dado por la razón entre la distribución posterior y la distribución a priori, que es equivalente a la razón entre la probabilidad de las observaciones bajo cada posible valor del parámetro, <span class="math inline">\(p(y \, | \, \theta)\)</span> o <em>likelihood</em>, y la probabilidad de las mismas observaciones promediadas por todos los posibles valores del parámetro, <span class="math inline">\(p(y)\)</span> o <em>marginal likelihood</em>:</p>
<p><span class="math display">\[ \frac{p(\theta\, | \,y)}{p(\theta)} = \frac{p(y\, | \,\theta)}{p(y)} \]</span></p>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> Este término es denominado razón de evidencia (<em>evidence ratio</em>) e indica en qué medida debe actualizarse la creencia probabilística sobre <span class="math inline">\(\theta\)</span>, codificada en la distribución a priori <span class="math inline">\(p(\theta)\)</span>, para convertirse en la distribución posterior <span class="math inline">\(p(\theta\, | \,y)\)</span>.</p>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> La idea fundamental en esta sección consiste en la generalización de esta perspectiva para comparar, directamente, distintas hipótesis o modelos:</p>
<p><span class="math display">\[ \frac{p(Modelo_{\,1}\, | \,y)}{p(Modelo_{\,0}\, | \,y)} = \frac{p(y\, | \,Modelo_{\,1})}{p(y\, | \,Modelo_{\,0})} \,\frac{p(Modelo_{\,1})}{p(Modelo_{\,0})} \]</span></p>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> Y la consecuente razón de evidencia es conocida con el nombre de factor de Bayes:</p>
<p><span class="math display">\[ \text{BF} = \frac{p(y\, | \,Modelo_{\,1})}{p(y\, | \,Modelo_{\,0})} \]</span></p>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> De esta manera, el factor de Bayes se corresponde con la razón de los <em>marginal likelihoods</em><a href="#fn10" class="footnoteRef" id="fnref10"><sup>10</sup></a> de cada modelo y cuantifican la magnitud en que los datos modifican las probabilidades que un investigador pone en cada hipótesis, interpretadas estas como creencias.</p>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> Volviendo al experimento sobre la intervención educativa, debemos comenzar especificando los modelos betabinomial y logístico cumulativo con distribuciones a priori sobre sus parámetros que representen nuestras hipótesis:</p>
<p><span class="math display">\[ k \, | \, n \sim \text{Binomial}(\theta, \text{n})\]</span> <span class="math display">\[ \theta \sim \text{Beta}(\alpha, \beta) \]</span> <span class="math display">\[ \alpha = \text{inverse logit}(\text{Intercept} + X\beta_{XM}) \, \left(\frac{1 - \text{rho}}{\text{rho}}\right) \]</span> <span class="math display">\[ \beta = \text{inverse logit}(\text{- Intercept} - X\beta_{XM}) \, \left(\frac{1 - \text{rho}}{\text{rho}}\right) \]</span> <span class="math display">\[ \alpha \sim \text{Normal}(0, 1) \]</span> <span class="math display">\[ \beta_{XM} \sim \text{HalfCauchy}(0, 1) \]</span> <span class="math display">\[ \text{rho} \sim \text{Uniform}(0, 1) \]</span></p>
<p><br></p>
<p><span class="math display">\[\text{logit}(Y \le j) = \alpha_j - X\beta^\prime_{XY_j} - M\beta^\prime_{MY}\]</span> <span class="math display">\[ \alpha_j \sim \text{Normal}(0, 1) \]</span> <span class="math display">\[ \beta^\prime_{XY_j} \sim \text{Normal}(0, 5) \]</span> <span class="math display">\[ \beta^\prime_{MY} \sim \text{HalfCauchy}(0, 1) \]</span></p>
<pre class="r"><code># Vamos a plotear las distribuciones a priori que representan las hipótesis de los investigadores:
par(mfrow = c(2, 3))

# Creamos una función para la distribución de densidad del halfcauchy:
halfcauchy &lt;- function(x) dcauchy(x, 0, 1) * as.integer(x&gt;=0) * as.integer(x&lt;Inf)
K &lt;- 1 / integrate(halfcauchy, 0, Inf)$value
dhalfcauchy &lt;- function(x) K * halfcauchy(x)
integrate(dhalfcauchy, -Inf, Inf) # Nos aseguramos de que la función integra a 1.
## 1 with absolute error &lt; 1.6e-10

curve(dnorm(x, 0, 1), xlim = c(-3, 3), main = expression(alpha), ylab = &quot;Densidad&quot;, xlab = &quot;&quot;)
# Centrando los predictores, al situar el intercepto en torno a 0 estamos concediendo la misma probabilidad a priori de 0.5 de administrar y no administrar el fármaco para todos los participantes antes de pasar por la intervención.

curve(dhalfcauchy(-x), xlim = c(-5, 1), main = expression(beta[XM]), ylab = &quot;Densidad&quot;, xlab = &quot;&quot;)
curve(dunif(x, 0, 1), xlim = c(0, 1), main = &quot;rho&quot;, xlab = NULL)

curve(dnorm(x, 0, 1), xlim = c(-3, 3), main = expression(alpha[j]), ylab = &quot;Densidad&quot;, xlab = &quot;&quot;)
# Centrando los predictores, al situar el intercepto en torno a 0 estamos concediendo la misma probabilidad a priori de 0.5 de seleccionar una categoría igual o menor para todos los participantes antes de pasar por la intervención.

curve(dhalfcauchy(-x), xlim = c(-5, 1), main = expression(beta*minute[MY]), ylab = &quot;Densidad&quot;, xlab = &quot;&quot;)
curve(dnorm(x, 0, 5), xlim = c(-15, 15), main = expression(beta*minute[XY[j]]), ylab = &quot;Densidad&quot;, xlab = &quot;&quot;)</code></pre>
<p><img src="TFG_files/figure-html/BF_1-1.png" width="960" style="display: block; margin: auto;" /></p>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> A continuación, podemos testar la presencia de un efecto mediacional basándonos en el método clásico del producto de coeficientes descrito en <span class="citation">Nuijten et al. (2015)</span>. En primer lugar, obtenemos el factor de Bayes que corresponde al efecto de la intervención sobre la probabilidad de administrar el fármaco comparando las predicciones del modelo betabinomial descrito anteriormente, al que denominaremos <span class="math inline">\(M_1\)</span>, con otro modelo similar pero sin el parámetro <span class="math inline">\(\beta_{XM}\)</span> y que llamaremos <span class="math inline">\(M_0\)</span>.</p>
<pre class="r"><code># Modelo betabinomial con el parámetro \beta_{XM}:
M1 &lt;- &quot;
// Primero declaramos los datos:
data {
int&lt;lower=1&gt; N; // N es un número entero que designa el número de observaciones.
int&lt;lower=0, upper=40&gt; Y[N]; // Y es un vector N de números enteros que designa el nñumero de administraciones del fármaco.
vector[N] Grupo; // Vector N que designa la intervención educativa.
}
// Centramos los predictores para que sea más sencillo situar los priors en los interceptos.
transformed data {
vector[N] Centered_Grupo;
Centered_Grupo = Grupo - mean(Grupo);
}
// Declaramos los parámetros:
parameters {
real intercept;
real beta_Grupo; // We could put &lt;upper=0&gt; here but it lowers the effective sample size.
real&lt;lower=0, upper=1&gt; rho; // Correlación[0, 1]
}
transformed parameters {
// Parámetros de la distribución beta:
    vector[N] alpha;
    vector[N] beta;
    for (n in 1:N) {
        alpha[n] = inv_logit(intercept + Centered_Grupo[n] * beta_Grupo) * (1 - rho) / rho;
        beta[n] = (1 - inv_logit(intercept + Centered_Grupo[n] * beta_Grupo)) * (1 - rho) / rho;
    }
}
model {
    target += normal_lpdf(intercept | 0, 1);
    target += cauchy_lpdf(beta_Grupo | 0, 1) - cauchy_lccdf(0 | 0, 1);
    target += uniform_lpdf(rho | 0, 1);
    for (n in 1:N) {
        target += beta_binomial_lpmf(Y[n] | 40, alpha[n], beta[n]); // Likelihood
    }
}
&quot;

# Modelo sin el parámetro \beta_{XM}:
M0 &lt;- &quot;
data {
int&lt;lower=1&gt; N; // number of observations.
int&lt;lower=0, upper=40&gt; Y[N];
}
parameters {
real intercept;
real&lt;lower=0, upper=1&gt; rho;
}
transformed parameters {
    vector[N] alpha;
    vector[N] beta;
    for (n in 1:N) {
        alpha[n] = inv_logit(intercept) * (1 - rho) / rho;
        beta[n] = (1 - inv_logit(intercept)) * (1 - rho) / rho;
    }
}
model {
target += normal_lpdf(intercept | 0, 1);
target += uniform_lpdf(rho | 0, 1);
for (n in 1:N) {
target += beta_binomial_lpmf(Y[n] | 40, alpha[n], beta[n]);
}
}
&quot;

# Compilamos los modelos:
model_M1 &lt;- stan_model(model_code = M1, model_name = &quot;stanmodel&quot;)
model_M0 &lt;- stan_model(model_code = M0, model_name = &quot;stanmodel&quot;)

data.list &lt;- list(N = nrow(mydata), Y = mydata$Si, Grupo = mydata$Grupo) # Preparamos los datos en una lista

# Tomamos muestras de la distribución posterior de los parámetros en cada modelo:
fit_M1 &lt;- sampling(model_M1, data = data.list, iter = 10000, warmup = 2000, chains = 4, cores = 4, control = list(adapt_delta = 0.8), seed = 1)
# Tras este comando se visualizará la progresión de las cadenas de montecarlo.
fit_M0 &lt;- sampling(model_M0, data = data.list, iter = 10000, warmup = 2000, chains = 4, cores = 4, control = list(adapt_delta = 0.8), seed = 1)

# Utilizamos el método Bridge sampling para estimar el marginal likelihood (en logaritmos):
ML_M1 &lt;- bridge_sampler(fit_M1, silent = TRUE)
ML_M0 &lt;- bridge_sampler(fit_M0, silent = TRUE)

# Errores de medida en la estimación de los marginal likelihoods:
# error_measures(ML_M1)$percentage
# error_measures(ML_M0)$percentage</code></pre>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> Igualmente, tenemos que computar la evidencia del parámetro <span class="math inline">\(\beta^\prime_{MY}\)</span> comparando las predicciones del modelo logístico cumulativo anterior (<span class="math inline">\(M_2\)</span>) con las del mismo modelo sin dicho parámetro (<span class="math inline">\(M_3\)</span>).</p>
<pre class="r"><code># A continuación ajustamos el modelo logístico cumulativo parcial con y sin el parámetro \beta^\prime_{MY}:

M2 &lt;- &quot;
// Stan no provee de ninguna función para aplicar este tipo de modelo por lo que creamos una función para aplicarlo:
functions { 
real cumulative_logit_lpmf(int Y, real eta1, real eta2, real eta3, real eta4, vector c) {
vector[5] p; // Vector de probabilidades de cada categoría.
p[1] = inv_logit(c[1] - eta1); 
p[2] = inv_logit(c[2] - eta2) - p[1];
p[3] = inv_logit(c[3] - eta3) - p[1] - p[2];
p[4] = inv_logit(c[4] - eta4) - p[1] - p[2] - p[3];
p[5] = 1 - p[1] - p[2] - p[3] - p[4];
return categorical_lpmf(Y | p); // Distribución categórica.
}
}
data {
int&lt;lower=0&gt; N;
int&lt;lower=1, upper=5&gt; Y[N];
matrix[N, 2] Predictors; // Matrix de predictores (No el design matrix).
}
// Centramos los predictores:
transformed data { 
matrix[N, 2] Centered_Predictors;
vector[2] Predictors_means;
for (i in 1:2) { 
Predictors_means[i] = mean(Predictors[, i]); 
Centered_Predictors[, i] = Predictors[, i] - Predictors_means[i]; 
}
}
parameters {
vector[4] betas; // Declaramos los coeficientes de la intervención para cada punto de corte.
real beta; // Coeficiente para el número de administraciones del fármaco.
ordered[4] c; // Interceptos cuando los predictores están centrados.
}
transformed parameters {
matrix[N, 4] eta;
for (n in 1:N) { 
    eta[n, 1] = Centered_Predictors[n, 1] * betas[1] + Centered_Predictors[n, 2] * beta;
    eta[n, 2] = Centered_Predictors[n, 1] * betas[2] + Centered_Predictors[n, 2] * beta;
    eta[n, 3] = Centered_Predictors[n, 1] * betas[3] + Centered_Predictors[n, 2] * beta;
    eta[n, 4] = Centered_Predictors[n, 1] * betas[4] + Centered_Predictors[n, 2] * beta;
}
}
model {
    target += cauchy_lpdf(betas | 0, 5);
    target += cauchy_lpdf(beta | 0, 1) - cauchy_lccdf(0 | 0, 1);
    target += normal_lpdf(c | 0, 1);
    for (n in 1:N) { 
        target += cumulative_logit_lpmf(Y[n] | eta[n, 1], eta[n, 2], eta[n, 3], eta[n, 4], c);
}
}
&quot;

# Repetimos el mismo modelo pero sin el parámetro de interés:
M3 &lt;- &quot;
functions { 
real cumulative_logit_lpmf(int Y, real eta1, real eta2, real eta3, real eta4, vector c) {
vector[5] p; 
p[1] = inv_logit(c[1] - eta1); 
p[2] = inv_logit(c[2] - eta2) - p[1];
p[3] = inv_logit(c[3] - eta3) - p[1] - p[2];
p[4] = inv_logit(c[4] - eta4) - p[1] - p[2] - p[3];
p[5] = 1 - p[1] - p[2] - p[3] - p[4];
return categorical_lpmf(Y | p); 
}
}
data {
int&lt;lower=0&gt; N;
int&lt;lower=1, upper=5&gt; Y[N];
matrix[N, 2] Predictors;
}
transformed data { 
matrix[N, 2] Centered_Predictors;
vector[2] Predictors_means;
for (i in 1:2) { 
Predictors_means[i] = mean(Predictors[, i]); 
Centered_Predictors[, i] = Predictors[, i] - Predictors_means[i]; 
}
}
parameters {
vector[4] betas;
ordered[4] c;
}
transformed parameters {
matrix[N, 4] eta;
for (n in 1:N) { 
    eta[n, 1] = Centered_Predictors[n, 1] * betas[1];
    eta[n, 2] = Centered_Predictors[n, 1] * betas[2];
    eta[n, 3] = Centered_Predictors[n, 1] * betas[3];
    eta[n, 4] = Centered_Predictors[n, 1] * betas[4];
}
}
model {
target += normal_lpdf(betas | 0, 5);
target += normal_lpdf(c | 0, 1);
for (n in 1:N) {
        target += cumulative_logit_lpmf(Y[n] | eta[n, 1], eta[n, 2], eta[n, 3], eta[n, 4], c);
}
}
&quot;

# Compilamos los modelos:
model_M2 &lt;- stan_model(model_code = M2, model_name = &quot;stanmodel&quot;)
model_M3 &lt;- stan_model(model_code = M3, model_name = &quot;stanmodel&quot;)

# Creamos una lista con los datos:
data.list &lt;- list(N = nrow(mydata), Y = mydata$Indicador, Predictors = cbind(mydata$Grupo, mydata$Si))

# Tomamos muestras de la distribución posterior de ambos modelos:
fit_M2 &lt;- sampling(model_M2, data = data.list, iter = 10000, warmup = 2000, chains = 4, cores = 4, init = 0,
                        control = list(adapt_delta = .995), seed = 1)
fit_M3 &lt;- sampling(model_M3, data = data.list, iter = 10000, warmup = 2000, chains = 4, cores = 4, init = 0,
                        control = list(adapt_delta = .99), seed = 1)

# Computamos el logaritmo de los marginal likelihoods:
ML_M2 &lt;- bridge_sampler(fit_M2, method = &quot;normal&quot;, silent = TRUE)
ML_M3 &lt;- bridge_sampler(fit_M3, method = &quot;normal&quot;, silent = TRUE)

# Errores de medida al computar los marginal likelihoods:
# error_measures(ML_M2)$percentage
# error_measures(ML_M3)$percentage</code></pre>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> De esta manera, si <span class="math inline">\(\text{BF}_{10} &gt; 1\)</span> y <span class="math inline">\(\text{BF}_{23} &gt; 1\)</span> entonces existe evidencia a favor del modelo <span class="math inline">\(M_1\)</span> y <span class="math inline">\(M_2\)</span>, respectivamente, indicando, a su vez, que existe evidencia a favor de la mediación. Sin embargo, la evidencia o factor de Bayes de este efecto mediacional es obtenido a través de la multiplicación de las probabilidades posteriores, para las cuales debemos especificar la credibilidad que concedemos a cada hipótesis (<span class="math inline">\(M_0\)</span>, <span class="math inline">\(M_1\)</span>, <span class="math inline">\(M_2\)</span>, <span class="math inline">\(M_3\)</span>):</p>
<p><br></p>
<p><span class="math display">\[ \text{BF}_{mediación} = \frac{p(M_1\, | \,y) \cdot p(M_2\, | \,y)}{1 - p(M_1\, | \,y) \cdot p(M_2\, | \,y)} \]</span></p>
<p><br></p>
<p><span class="math display">\[ \frac{p(M_1\, | \,y)}{p(M_0\, | \,y)} = \text{BF}_{10} \, \frac{p(M_1)}{p(M_0)} \]</span></p>
<pre class="r"><code>BF10 &lt;- bf(ML_M1, ML_M0)$bf # Factor de Bayes
BF10
## [1] 523.2004</code></pre>
<p><span class="math display">\[ \frac{p(M_2\, | \,y)}{p(M_3\, | \,y)} = \text{BF}_{23} \, \frac{p(M_2)}{p(M_3)} \]</span></p>
<pre class="r"><code>BF23 &lt;- bf(ML_M2, ML_M3)$bf # Factor de Bayes.
BF23
## [1] 141188650983</code></pre>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> Siguiendo estos pasos, se estima que los datos obtenidos en el experimento son 523 veces más probables de observar en el modelo betabinomial con el parámetro <span class="math inline">\(\beta_{XM}\)</span> (<span class="math inline">\(M_1\)</span>) que en el mismo modelo sin dicho parámetro (<span class="math inline">\(M_0\)</span>), es decir, <span class="math inline">\(\text{BF}_{10} \simeq 523\)</span>. Por contraparte, <span class="math inline">\(\text{BF}_{23}\)</span> arroja una cifra de 12 dígitos (<span class="math inline">\(1.4 \cdot 10^{11}\)</span>), es decir, una evidencia tan grande a favor del modelo ordinal con el parámetro <span class="math inline">\(\beta^\prime_{MY}\)</span> (<span class="math inline">\(M_2\)</span>) que podría modificar cualquier creencia a favor del mismo modelo sin dicho parámetro (<span class="math inline">\(M_3\)</span>). Una vez obtenidos estos valores, procedemos a computar la probabilidad posterior de <span class="math inline">\(M_0\)</span>, <span class="math inline">\(M_1\)</span>, <span class="math inline">\(M_2\)</span> y <span class="math inline">\(M_3\)</span> asignando nuestras creencias previas, en forma de probabilidad, en dichas hipótesis. Por ejemplo, podemos mostrarnos escépticos y pensar que <span class="math inline">\(p(M_1) = p(M_2) = 0.25\)</span> y <span class="math inline">\(p(M_0) = p(M_3) = 0.75\)</span>, en cuyo caso</p>
<p><span class="math display">\[\frac{p(Modelo_{\,1})}{p(Modelo_{\,0})} = \frac{p(Modelo_{\,2})}{p(Modelo_{\,3})} = \frac{1}{3}.\]</span></p>
<p>Esto quiere decir que, antes de observar los datos, creemos que los modelos sin el parámetro extra son 3 veces más probables. Así, tenemos que</p>
<p><br></p>
<p><span class="math display">\[ \frac{p(M_1\, | \,y)}{p(M_0\, | \,y)} = \text{BF}_{10} \, \frac{p(M_1)}{p(M_0)} \simeq 523 \cdot \frac{0.25}{0.75} \simeq 174.4 \]</span></p>
<pre class="r"><code>BF10 * (1/3)
## [1] 174.4001</code></pre>
<p><span class="math display">\[ p(M_1\, | \,y) \simeq \frac{174.4}{1 + 174.4} \simeq 0.994 \]</span></p>
<pre class="r"><code>post_prob_M1_M0 &lt;- post_prob(ML_M1, ML_M0, prior_prob = c(.25, .75))
post_prob_M1_M0[1]
##     ML_M1 
## 0.9942987</code></pre>
<p><span class="math display">\[ \frac{p(M_2\, | \,y)}{p(M_3\, | \,y)} = \text{BF}_{23} \, \frac{p(M_2)}{p(M_3)} \simeq 1.4 \cdot 10^{11} \cdot \frac{0.25}{0.75} \simeq 4.7 \cdot 10^{10} \]</span></p>
<pre class="r"><code>BF23 * (1/3)
## [1] 47062883661</code></pre>
<p><span class="math display">\[ p(M_2\, | \,y) \simeq 1 \]</span></p>
<pre class="r"><code>post_prob_M2_M3 &lt;- post_prob(ML_M2, ML_M3, prior_prob = c(.25, .75))
post_prob_M2_M3[1]
## ML_M2 
##     1</code></pre>
<p><span class="math display">\[\text{probabilidad de mediación} = p(M_1\, | \,y) \cdot p(M_2\, | \,y) \simeq 0.994 \]</span></p>
<pre class="r"><code># Probabilidad de mediación:
(post_prob_M1_M0[1] * post_prob_M2_M3[1])
##     ML_M1 
## 0.9942987</code></pre>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> lo que quiere decir que</p>
<p><span class="math display">\[\text{BF}_{mediación} \simeq \frac{0.994}{1 - 0.994} \simeq 174.4\]</span></p>
<p><br></p>
<pre class="r"><code># Factor de Bayes de la mediación:
BF_mediacion &lt;- (post_prob_M1_M0[1] * post_prob_M2_M3[1]) / ( 1 - post_prob_M1_M0[1] * post_prob_M2_M3[1])
BF_mediacion
##    ML_M1 
## 174.4001</code></pre>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> Estos resultados nos indican que los datos observados son 174 veces más probables bajo la hipótesis mediacional compuesta por <span class="math inline">\(M_1\)</span> y <span class="math inline">\(M_2\)</span> que la no mediacional, compuesta por <span class="math inline">\(M_0\)</span> y <span class="math inline">\(M_3\)</span>.</p>
<p><br></p>
</div>
<div id="factor-de-bayes-reportado-en-barberia2018" class="section level1">
<h1>Factor de Bayes reportado en <span class="citation">Barberia (2018)</span></h1>
<p><br></p>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> Los autores del paper original <span class="citation">(Barberia 2018)</span> reportaron un t-test bayesiano ordinario con varianzas equivalentes entre grupos. Aunque este método es computacionalmente menos eficiente, también podemos aproximar el factor de Bayes especificando el t-test en Stan y usando <em>bridge sampling</em>. La parametrización de este modelo está especificado en <span class="citation">Wetzels et al. (2009)</span> con la diferencia de presentar las siguientes distribuciones a priori:</p>
<p><span class="math display">\[ \mu \sim \text{Cauchy}(0, 1) \]</span> <span class="math display">\[ \delta \sim \text{HalfCauchy}(0, .7071) \]</span> <span class="math display">\[ \sigma \sim \frac{1}{\sigma} \]</span></p>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> Los <em>likelihoods</em> son:</p>
<p><span class="math display">\[ Y_1 \sim \text{Normal}(\mu - \mu_{diferencia} \, \cdot \, \alpha\,{_0}, \sigma)\]</span> <span class="math display">\[ Y_0 \sim \text{Normal}(\mu + \mu_{diferencia} \, \cdot \, \alpha{\,_1}, \sigma)\]</span> donde, <span class="math inline">\(Y_1\)</span> representa a los participantes que reciben la intervención, <span class="math inline">\(Y_2\)</span> representa a los que no reciben la intervención, <span class="math inline">\(\mu\)</span> es el <em>grand mean</em>, <span class="math inline">\(\mu_{diferencia}\)</span> es la diferencia media entre grupos, <span class="math inline">\(\alpha{\,_0}\)</span> es la proporción de participantes en el grupo control y <span class="math inline">\(\alpha{\,_1}\)</span> es la del grupo de intervención.</p>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> La hipótesis nula descarta el parámetro <span class="math inline">\(\delta\)</span>, que es el tamaño del efecto estandarizado:</p>
<p><span class="math display">\[ \delta = \frac{\mu_{diferencia}}{\sigma} \]</span></p>
<pre class="r"><code># Este es el resultado reportado en el paper:
ttestBF(formula = Causal_Judgment ~ Group, data = data, nullInterval = c(0, Inf), rscale = 1/sqrt(2))
## Bayes factor analysis
## --------------
## [1] Alt., r=0.707 0&lt;d&lt;Inf    : 0.05095193 ±0.12%
## [2] Alt., r=0.707 !(0&lt;d&lt;Inf) : 47.68974   ±0%
## 
## Against denominator:
##   Null, mu1-mu2 = 0 
## ---
## Bayes factor type: BFindepSample, JZS</code></pre>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> El factor de Bayes es de 47.69 a favor de la hipótesis alternativa.</p>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> Vamos a parametrizar este modelo en Stan:</p>
<pre class="r"><code>Y1 &lt;- data$Causal_Judgment[mydata$Grupo == 1]
Y0 &lt;- data$Causal_Judgment[mydata$Grupo == 0]
n1 &lt;- length(data$Group[mydata$Grupo == 1])
n0 &lt;- length(data$Group[mydata$Grupo == 0])
data.list &lt;- list(n0 = n0, n1 = n1, ratio_1 = n1/nrow(data), ratio_0 = n0/nrow(data), Y1 = Y1, Y0 = Y0)

# Hipótesis nula:
Null &lt;- &quot;
data {
int&lt;lower=1&gt; n1; // Número de participantes en la condición de intervención.
int&lt;lower=1&gt; n0; // Número de participantes en la condición de no intervención.
vector[n1] Y1; // Observaciones en la condición de intervención.
vector[n0] Y0; // Observaciones en la condición de no intervención.
}
parameters {
real mu;
real&lt;lower=0&gt; sigma; // Desviación típica.
}
model {
target += cauchy_lpdf(mu | 0, 1); // Cauchy prior en la media.
target += log(1/sigma); // Jeffreys prior en la desviación típica.
// En este modelo nulo asumimos que no hay diferencias entre grupos por lo que ajustamos el mismo likelihood a ambos:
target += normal_lpdf(Y1 | mu, sigma); // likelihood
target += normal_lpdf(Y0 | mu, sigma); // likelihood
}
&quot;

# Hipótesis alternativa:
Alternative &lt;- &quot;
data {
int&lt;lower=1&gt; n1; // Número de participantes en la condición de intervención.
int&lt;lower=1&gt; n0; // Número de participantes en la condición de no intervención.
vector[n1] Y1; // Observaciones en la condición de intervención.
vector[n0] Y0; // Observaciones en la condición de no intervención.
real&lt;lower=0, upper=1&gt; ratio_1; // Proporción de participantes en el grupo de intervención.
real&lt;lower=0, upper=1&gt; ratio_0; // Proporción de participantes en el grupo control.
}
parameters {
real mu; // El grand mean.
real delta; // Efecto estandarizado.
real&lt;lower=0&gt; sigma; // Desviación típica.
}

model {
target += cauchy_lpdf(mu | 0, 1); // Cauchy prior en el grand mean.
target += cauchy_lpdf(delta | 0, 1 / sqrt(2)) - cauchy_lccdf(0 | 0, 1 / sqrt(2)); // Half Cauchy prior en delta
target += log(1/sigma); // Jeffreys prior en la desviación típica.
target += normal_lpdf(Y1 | mu - delta * sigma * ratio_0, sigma); // likelihood para el grupo de intervención.
target += normal_lpdf(Y0 | mu + delta * sigma * ratio_1, sigma); // likelihood para el grupo de no intervención.
}
&quot;

# Compilamos los modelos:
Null_model &lt;- stan_model(model_code = Null, model_name = &quot;stanmodel&quot;)
Alternative_model &lt;- stan_model(model_code = Alternative, model_name = &quot;stanmodel&quot;)

# Tomamos muestras de las distribuciones posteriores:
Null_fit &lt;- sampling(Null_model, data = data.list, iter = 20000, warmup = 1000, chains = 4, cores = 4,
                        control = list(adapt_delta = .99), seed = 1)
Alternative_fit &lt;- sampling(Alternative_model, data = data.list, iter = 20000, warmup = 1000, chains = 4, cores = 4,
                        control = list(adapt_delta = .99), seed = 1)
# Obtenemos los marginal likelihoods a través del método bridge sampling:
ML_Null &lt;- bridge_sampler(Null_fit, silent = TRUE)
ML_Alternative &lt;- bridge_sampler(Alternative_fit, silent = TRUE)

# Errores de medida en la computación de los marginal likelihoods
error_measures(ML_Null)$percentage
error_measures(ML_Alternative)$percentage</code></pre>
<pre><code>## [1] &quot;0.0288%&quot;
## [1] &quot;0.0297%&quot;</code></pre>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> Computamos el factor de Bayes a favor de la hipótesis con el parámetro <span class="math inline">\(\delta\)</span>:</p>
<pre class="r"><code>BF_Alternative_Null &lt;- bf(ML_Alternative, ML_Null) # Factor de Bayes.
BF_Alternative_Null</code></pre>
<pre><code>## The estimated Bayes factor in favor of x1 over x2 is equal to: 47.68639</code></pre>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> Es muy difícil que las hipótesis que un investigador quiere contrastar estén disponibles por defecto en los paquetes estadísticos actuales y probablemente nunca sean lo suficientemente flexibles para adaptarlas. Sin embargo, con Stan <span class="citation">(Stan Development Team 2018)</span> y el paquete <em>brigdesampling</em> <span class="citation">(Gronau and Singmann 2017)</span> siempre podremos especificar nuestra hipótesis y obtener el factor de Bayes.</p>
<pre class="r"><code># Para liberar memoria:
rm(fit_M0, fit_M1, fit_M2, fit_M3)</code></pre>
<p><br></p>
</div>
<div id="analisis-bayesiano" class="section level1">
<h1>Análisis bayesiano</h1>
<p><br></p>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> A diferencia del método anterior, el análisis bayesiano tradicional no pretende comparar modelos asignándoles probabilidades ni representar una hipótesis a través de distribuciones a priori en los parámetros. En su lugar, pretende obtener la distribución posterior de cada uno de ellos a partir de distribuciones a priori que asignan una mayor probabilidad a los valores más razonables y sancionan los menos razonables. De esta forma, el análisis bayesiano se puede considerar un método que optimiza o regulariza los resultados incorporando en la inferencia el conocimiento previo que los investigadores poseen acerca de los parámetros.</p>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> En este caso simplemente queremos obtener la distribución de probabilidad posterior de los parámetros condicionando en los datos observados <span class="math inline">\(p(\theta \, | \, y)\)</span>. Por tanto, tan solo debemos volver a ajustar los anteriores modelos. También utilizaremos las mismas distribuciones a priori para mantener el análisis simple.</p>
<p><strong>Modelo betabinomial</strong>:</p>
<pre class="r"><code># Esta vez utilizaremos el bloque denominado *generated quantities* para simular los datos necesarios para comprobar la adecuación del modelo a los datos observados.

# Modelo betabinomial:
betabinomial &lt;- &quot;
data {
int&lt;lower=1&gt; N;
int&lt;lower=0, upper=40&gt; Y[N];
vector[N] Grupo;
}
transformed data {
vector[N] Centered_Grupo;
Centered_Grupo = Grupo - mean(Grupo);
}
parameters {
real intercept;
real beta_Grupo; // We could put &lt;upper=0&gt; but it lowers the effective sample size.
real&lt;lower=0, upper=1&gt; rho;
}
transformed parameters {
vector[N] alpha;
vector[N] beta;
for (n in 1:N) {
alpha[n] = inv_logit(intercept + Centered_Grupo[n] * beta_Grupo) * (1 - rho) / rho;
beta[n] = (1 - inv_logit(intercept + Centered_Grupo[n] * beta_Grupo)) * (1 - rho) / rho;
}
}
model {
target += normal_lpdf(intercept | 0, 1);
target += cauchy_lpdf(beta_Grupo | 0, 1) - cauchy_lccdf(0 | 0, 1);
target += uniform_lpdf(rho | 0, 1);
for (n in 1:N) {
target += beta_binomial_lpmf(Y[n] | 40, alpha[n], beta[n]);
}
}
generated quantities {
real Intercept;
vector[N] log_lik; // Este es el logaritmo del likelihood, que nunca está de más para computar varias cosas como WAIC o LOO.
vector[N] posterior_predictions; // Estos son valores predichos del modelo. Comprobaremos si se adecúan a los observados (posterior predictive checks).
vector[N] M1; // Simulamos el número de administraciones del fármaco bajo no intervención.
vector[N] M0; // Simulamos el número de administraciones del fármaco bajo intervención.
Intercept = intercept - mean(Grupo) * beta_Grupo;
for(n in 1:N) {
log_lik[n] = beta_binomial_lpmf(Y[n] | 40, alpha[n], beta[n]);
posterior_predictions[n] = beta_binomial_rng(40, alpha[n], beta[n]);
M1[n] = beta_binomial_rng(40, inv_logit(Intercept + 1 * beta_Grupo) * (1 - rho) / rho, 
(1 - inv_logit(Intercept + 1 * beta_Grupo)) * (1 - rho) / rho);
M0[n] = beta_binomial_rng(40, inv_logit(Intercept) * (1 - rho) / rho, (1 - inv_logit(Intercept)) * (1 - rho) / rho);
}
}
&quot;

data.list &lt;- list(N = nrow(mydata), Y = mydata$Si, Grupo = mydata$Grupo)
modelo_betabinomial &lt;- stan_model(model_code = betabinomial, model_name = &quot;stanmodel&quot;)

# Se recomienda tomar menos muestras reduciendo el número de iteraciones de 27000 a 10000. De lo contrario, el proceso será largo.
# Rebajar &quot;cores = 8&quot; al número de núcleos disponibles.
fit_modelo_betabinomial &lt;- sampling(modelo_betabinomial, data = data.list, chains = 4, control = list(adapt_delta = 0.8),
                iter = 10000, warmup = 2000, cores = 8, seed = 1)
# Se extraen 10000 muestras por cadena, descartando las 2000 primeras (período de adaptación de la cadena montecarlo). En total extraemos 32 muestras de la distribución posterior.

print(fit_modelo_betabinomial, probs = c(0.025, 0.5, 0.975), pars = c(&quot;Intercept&quot;, &quot;beta_Grupo&quot;))</code></pre>
<pre><code>## Inference for Stan model: stanmodel.
## 4 chains, each with iter=10000; warmup=2000; thin=1; 
## post-warmup draws per chain=8000, total post-warmup draws=32000.
## 
##             mean se_mean   sd  2.5%   50% 97.5% n_eff Rhat
## Intercept   0.47       0 0.13  0.22  0.47  0.72 32000    1
## beta_Grupo -0.75       0 0.19 -1.14 -0.75 -0.38 32000    1
## 
## Samples were drawn using NUTS(diag_e) at Mon May 28 23:02:35 2018.
## For each parameter, n_eff is a crude measure of effective sample size,
## and Rhat is the potential scale reduction factor on split chains (at 
## convergence, Rhat=1).</code></pre>
<p><strong>Modelo logístico cumulativo parcial</strong>:</p>
<pre class="r"><code>ordinal &lt;- &quot;
functions { 
real cumulative_logit_lpmf(int Y, real eta1, real eta2, real eta3, real eta4, vector c) {
vector[5] p; 
p[1] = inv_logit(c[1] - eta1); 
p[2] = inv_logit(c[2] - eta2) - p[1];
p[3] = inv_logit(c[3] - eta3) - p[1] - p[2];
p[4] = inv_logit(c[4] - eta4) - p[1] - p[2] - p[3];
p[5] = 1 - p[1] - p[2] - p[3] - p[4];
return categorical_lpmf(Y | p); 
}
}
data {
int&lt;lower=0&gt; N; // number of observations.
int&lt;lower=1, upper=5&gt; Y[N];
matrix[N, 2] Predictors;
}
transformed data { 
matrix[N, 2] Centered_Predictors;
vector[2] Predictors_means;
for (i in 1:2) { 
Predictors_means[i] = mean(Predictors[, i]); 
Centered_Predictors[, i] = Predictors[, i] - Predictors_means[i]; 
}
}
parameters {
vector[4] betas;
real beta;
ordered[4] c; // Intercepts.
}
transformed parameters {
matrix[N, 4] eta;
for (n in 1:N) { 
eta[n, 1] = Centered_Predictors[n, 1] * betas[1] + Centered_Predictors[n, 2] * beta;
eta[n, 2] = Centered_Predictors[n, 1] * betas[2] + Centered_Predictors[n, 2] * beta;
eta[n, 3] = Centered_Predictors[n, 1] * betas[3] + Centered_Predictors[n, 2] * beta;
eta[n, 4] = Centered_Predictors[n, 1] * betas[4] + Centered_Predictors[n, 2] * beta;
}
}
model {
target += cauchy_lpdf(betas | 0, 5);
target += cauchy_lpdf(beta | 0, 1) - cauchy_lccdf(0 | 0, 1);
target += normal_lpdf(c | 0, 1);
for (n in 1:N) { 
target += cumulative_logit_lpmf(Y[n] | eta[n, 1], eta[n, 2], eta[n, 3], eta[n, 4], c);
}
}
generated quantities {
vector[4] Intercepts;
matrix[N, 5] p;
vector[5] probs;
vector[N] log_lik;
vector[N] posterior_predictions;
Intercepts = c + Predictors_means[1] * betas[1:4] + Predictors_means[2] * beta;
for (n in 1:N) {
p[n, 1] = inv_logit(c[1] - eta[n, 1]); 
p[n, 2] = inv_logit(c[2] - eta[n, 2]) - p[n, 1];
p[n, 3] = inv_logit(c[3] - eta[n, 3]) - p[n, 1] - p[n, 2];
p[n, 4] = inv_logit(c[4] - eta[n, 4]) - p[n, 1] - p[n, 2] - p[n, 3];
p[n, 5] = 1 - p[n, 1] - p[n, 2] - p[n, 3] - p[n, 4];
probs[1] = p[n, 1]; probs[2] = p[n, 2]; probs[3] = p[n, 3]; probs[4] = p[n, 4]; probs[5] = p[n, 5];
log_lik[n] = categorical_lpmf(Y[n] | probs);
posterior_predictions[n] = categorical_rng(probs);
    }
}
&quot;

data.list &lt;- list(N = nrow(mydata), Y = mydata$Indicador, Predictors = cbind(mydata$Grupo, mydata$Si))
modelo_ordinal &lt;- stan_model(model_code = ordinal, model_name = &quot;stanmodel&quot;)
fit_modelo_ordinal &lt;- sampling(modelo_ordinal, data = data.list, chains = 4, init = 0, control = list(adapt_delta = 0.995),
                iter = 10000, warmup = 2000, cores = 8, seed = 1)
# Existen 4 divergencias (comportamiento extraño de las cadenas) pero son inofensivas.

print(fit_modelo_ordinal, probs = c(0.025, 0.5, 0.975), pars = c(&quot;Intercepts&quot;, &quot;betas&quot;, &quot;beta&quot;))</code></pre>
<pre><code>## Inference for Stan model: stanmodel.
## 4 chains, each with iter=10000; warmup=2000; thin=1; 
## post-warmup draws per chain=8000, total post-warmup draws=32000.
## 
##                mean se_mean   sd  2.5%   50% 97.5% n_eff Rhat
## Intercepts[1]  2.10    0.00 0.67  0.81  2.09  3.45 21797    1
## Intercepts[2]  2.95    0.00 0.66  1.71  2.92  4.29 22441    1
## Intercepts[3]  4.54    0.00 0.71  3.19  4.52  5.98 21140    1
## Intercepts[4]  6.66    0.01 0.88  5.03  6.63  8.47 21205    1
## betas[1]      -0.51    0.00 0.53 -1.56 -0.50  0.53 18655    1
## betas[2]      -0.26    0.00 0.48 -1.20 -0.26  0.68 18606    1
## betas[3]      -0.25    0.00 0.48 -1.18 -0.26  0.68 22116    1
## betas[4]      -0.73    0.01 0.82 -2.44 -0.69  0.78 20903    1
## beta           0.18    0.00 0.03  0.13  0.18  0.24 21778    1
## 
## Samples were drawn using NUTS(diag_e) at Mon May 28 23:05:04 2018.
## For each parameter, n_eff is a crude measure of effective sample size,
## and Rhat is the potential scale reduction factor on split chains (at 
## convergence, Rhat=1).</code></pre>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> A continuación podemos realizar algunos diagnósticos del comportamiento de las cadenas de Markov y extraer los parámetros y otros objetos para explorar las implicaciones de los modelos:</p>
<p><strong>Modelo Betabinomial</strong>:</p>
<pre class="r"><code>betabinomial_chains &lt;- mcmc_trace(as.array(fit_modelo_betabinomial), pars = c(&quot;Intercept&quot;, &quot;beta_Grupo&quot;))

# Extraemos el logaritmo del likelihood:
betabinomial_log_lik &lt;- extract_log_lik(fit_modelo_betabinomial)
# Computamos LOO, que es mejor que WAIC y es una medida que podemos usar para comparar modelos.
betabinomial_n_eff &lt;- relative_eff(exp(betabinomial_log_lik), chain_id = rep(1:4, each = nrow(betabinomial_log_lik) / 4), cores = 4)
betabinomial_loo &lt;- loo(betabinomial_log_lik, r_eff = betabinomial_n_eff, cores = 4)
betabinomial_waic &lt;- waic(betabinomial_log_lik, cores = 4) # También computamos WAIC.

# Extraemos las estimaciones de los parámetros:
post_modelo_betabinomial &lt;- extract(fit_modelo_betabinomial, 
                                    pars = c(&#39;posterior_predictions&#39;, &quot;Intercept&quot;, &quot;alpha&quot;, &quot;beta&quot;, &quot;beta_Grupo&quot;, &quot;rho&quot;, &#39;M1&#39;, &#39;M0&#39;))

# Vamos a visualizar la distribución beta media que sigue la probabilidad de administrar el fármaco para cada condición (intervención y no intervención).
betabinomial_alpha &lt;- apply(post_modelo_betabinomial$alpha, FUN = mean, MARGIN = 2)
betabinomial_beta &lt;- apply(post_modelo_betabinomial$beta, FUN = mean, MARGIN = 2)
alphas_control &lt;- as.numeric(post_modelo_betabinomial$alpha[, 1:47])
betas_control &lt;- as.numeric(post_modelo_betabinomial$beta[, 1:47])
alphas_intervention &lt;- as.numeric(post_modelo_betabinomial$alpha[, 48:106])
betas_intervention &lt;- as.numeric(post_modelo_betabinomial$beta[, 48:106])

# Comprobamos si las simulaciones del modelo se corresponden con los datos observados (posterior predictive checks):
# Proporción de administraciones del fármaco de cada participante (debería ser la misma entre los miembros del mismo grupo):
individual_probs &lt;- apply(post_modelo_betabinomial$posterior_predictions, FUN = function(x) mean(x) / 40, MARGIN = 2)
intervencion_prob &lt;- mean(individual_probs[mydata$Grupo == 1])
control_prob &lt;- mean(individual_probs[mydata$Grupo == 0])</code></pre>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> Comprobamos si las cadenas de Markov se comportan bien:</p>
<pre class="r"><code>check_all_diagnostics(fit_modelo_ordinal)
## [1] &quot;n_eff / iter looks reasonable for all parameters&quot;
## [1] &quot;Rhat looks reasonable for all parameters&quot;
## [1] &quot;4 of 32000 iterations ended with a divergence (0.0125%)&quot;
## [1] &quot;  Try running with larger adapt_delta to remove the divergences&quot;
## [1] &quot;0 of 32000 iterations saturated the maximum tree depth of 10 (0%)&quot;
## [1] &quot;E-BFMI indicated no pathological behavior&quot;
betabinomial_chains</code></pre>
<p><img src="TFG_files/figure-html/Bayesian_analysis_6-1.png" width="480" style="display: block; margin: auto;" /></p>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> Visualizamos LOO, WAIC, las distribuciones de probabilidad predichas por el modelo y realizamos un par de <em>posterior predictive checks</em>:</p>
<pre class="r"><code># Visualizamos LOO y WAIC:
print(betabinomial_loo, digits = 3)
## 
## Computed from 32000 by 106 log-likelihood matrix
## 
##          Estimate    SE
## elpd_loo -384.351 4.332
## p_loo       3.763 0.743
## looic     768.701 8.664
## ------
## Monte Carlo SE of elpd_loo is 0.013.
## 
## All Pareto k estimates are good (k &lt; 0.5).
## See help(&#39;pareto-k-diagnostic&#39;) for details.
print(betabinomial_waic, digits = 3)
## 
## Computed from 32000 by 106 log-likelihood matrix
## 
##           Estimate    SE
## elpd_waic -384.342 4.330
## p_waic       3.754 0.740
## waic       768.684 8.660
# Si ajustamos otros modelos, podemos compararlos usando estas magnitudes.

# Comprobamos si nuestro modelo acomoda bien los datos observados (posterior predictive checks):
intervencion_prob # Proporción estimada por nuestro modelo en el grupo de intervención.
## [1] 0.4297853
mean((mydata$Si / 40)[mydata$Grupo == 1]) # Proporción observada en el grupo de intervención.
## [1] 0.4361702

control_prob # Proporción estimada por nuestro modelo en el grupo de no intervención.
## [1] 0.6140977
mean((mydata$Si / 40)[mydata$Grupo == 0]) # Proporción observada en el grupo de no intervención.
## [1] 0.6122881

# Nuestro modelo describe bien el proceso que ha generado los datos.

# Visualizamos la distribución de la probabilidad de administrar el fármaco en la condición de intervención y de no intervención en su valor promediado y otras 100 distribuciones simuladas aleatoriamente de la distribución posterior de alpha y beta:
curve(dbeta(x, shape1 = unique(betabinomial_alpha)[1], shape2 = unique(betabinomial_beta)[1]), ylim = c(0, 2), col = &quot;black&quot;, ylab = &quot;Densidad&quot;, xlab = &quot;Probabilidad&quot;, lwd = 0)

for(i in 1:100) {
curve(dbeta(x, shape1 = sample(alphas_control, 1), shape2 = sample(betas_control, 1)), add = T,  col = &quot;blue&quot;)
curve(dbeta(x, shape1 = sample(alphas_control, 1), shape2 = sample(betas_control, 1)), add = T,  col = &quot;blue&quot;)

curve(dbeta(x, shape1 = sample(alphas_intervention, 1), shape2 = sample(betas_intervention, 1)), add = T,  col = &quot;red&quot;)
curve(dbeta(x, shape1 = sample(alphas_intervention, 1), shape2 = sample(betas_intervention, 1)), add = T,  col = &quot;red&quot;)
}

# Distribuciones promediadas:
curve(dbeta(x, shape1 = unique(betabinomial_alpha)[1], shape2 = unique(betabinomial_beta)[1]), ylim = c(0, 2), col = &quot;black&quot;, ylab = &quot;Density&quot;, xlab = &quot;Probability&quot;, add = T, lwd = 2)
curve(dbeta(x, shape1 = unique(betabinomial_alpha)[2], shape2 = unique(betabinomial_beta)[2]), add = T,  col = &quot;black&quot;, lwd = 2)</code></pre>
<p><img src="TFG_files/figure-html/Bayesian_analysis_7-1.png" width="576" style="display: block; margin: auto;" /></p>
<pre class="r"><code>
# Podemos comprobar que el grupo que no recibe la intervención (rojo) presenta mayor probabilidad de administrar el fármaco.</code></pre>
<p><strong>Modelo logístico cumulativo parcial</strong>:</p>
<pre class="r"><code># Comprobamos las cadenas de montecarlo para diagnosticar alguna anomalía en las estimaciones:
ordinal_chains &lt;- mcmc_trace(as.array(fit_modelo_ordinal), pars = c(&quot;Intercepts[1]&quot;, &quot;Intercepts[2]&quot;, &quot;Intercepts[3]&quot;, &quot;Intercepts[4]&quot;, &quot;betas[1]&quot;, &quot;betas[2]&quot;, &quot;betas[3]&quot;, &quot;betas[4]&quot;, &quot;beta&quot;))

ordinal_log_lik &lt;- extract_log_lik(fit_modelo_ordinal)
ordinal_n_eff &lt;- relative_eff(exp(ordinal_log_lik), chain_id = rep(1:4, each = nrow(ordinal_log_lik) / 4), cores = 4)
ordinal_loo &lt;- loo(ordinal_log_lik, r_eff = ordinal_n_eff, cores = 4)
ordinal_waic &lt;- waic(ordinal_log_lik, cores = 1)

# Distribuciones posteriores de los parámetros:
ordinal_parameters &lt;- mcmc_dens(as.array(fit_modelo_ordinal), pars = c(&quot;Intercepts[1]&quot;, &quot;Intercepts[2]&quot;, &quot;Intercepts[3]&quot;, 
                                                 &quot;Intercepts[4]&quot;, &quot;betas[1]&quot;, &quot;betas[2]&quot;, &quot;betas[3]&quot;, &quot;betas[4]&quot;, &quot;beta&quot;))

# Extraemos del modelo los parámetros u objetos que nos interesan:
post_modelo_ordinal &lt;- extract(fit_modelo_ordinal, pars = c(&#39;posterior_predictions&#39;, &#39;Intercepts&#39;, &#39;betas&#39;, &#39;beta&#39;))
# Así podemos plotear nosotros mismos los parámetros:

# Posterior predictive checks: comprobamos si las simulaciones del modelo se ajustan a las observaciones del dataset:
scores_by_category &lt;- table(as.numeric(post_modelo_ordinal$posterior_predictions)) / 32000
# Podemos realizar otros posterior predictive checks. Por ejemplo, haciendo lo mismo pero por grupo:
indice &lt;- rep(mydata$Grupo, 32000)
scores_by_category_intervencion &lt;- table(as.numeric(t(post_modelo_ordinal$posterior_predictions))[indice == 1]) / 32000
scores_by_category_control &lt;- table(as.numeric(t(post_modelo_ordinal$posterior_predictions))[indice == 0]) / 32000</code></pre>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> Comprobamos el comportamiento de las cadenas de Markov:</p>
<pre class="r"><code>check_all_diagnostics(fit_modelo_ordinal)
## [1] &quot;n_eff / iter looks reasonable for all parameters&quot;
## [1] &quot;Rhat looks reasonable for all parameters&quot;
## [1] &quot;4 of 32000 iterations ended with a divergence (0.0125%)&quot;
## [1] &quot;  Try running with larger adapt_delta to remove the divergences&quot;
## [1] &quot;0 of 32000 iterations saturated the maximum tree depth of 10 (0%)&quot;
## [1] &quot;E-BFMI indicated no pathological behavior&quot;
ordinal_chains</code></pre>
<p><img src="TFG_files/figure-html/Bayesian_analysis_9-1.png" width="960" style="display: block; margin: auto;" /></p>
<pre class="r"><code># También podemos realizar distintas comprobaciones mediante la siguiente herramienta en línea:
# shinystan::launch_shinystan(fit_modelo_ordinal)</code></pre>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> Visualizamos LOO, WAIC, la distribución posterior de los parámetros y realizamos algunos <em>posterior predictive checks</em>:</p>
<pre class="r"><code>ordinal_parameters</code></pre>
<p><img src="TFG_files/figure-html/Bayesian_analysis_10-1.png" width="960" style="display: block; margin: auto;" /></p>
<pre class="r"><code>print(ordinal_loo, digits = 3)
## 
## Computed from 32000 by 106 log-likelihood matrix
## 
##          Estimate     SE
## elpd_loo -131.290  6.576
## p_loo       7.834  0.644
## looic     262.580 13.152
## ------
## Monte Carlo SE of elpd_loo is 0.020.
## 
## All Pareto k estimates are good (k &lt; 0.5).
## See help(&#39;pareto-k-diagnostic&#39;) for details.
print(ordinal_waic, digits = 3)
## 
## Computed from 32000 by 106 log-likelihood matrix
## 
##           Estimate     SE
## elpd_waic -131.259  6.572
## p_waic       7.803  0.637
## waic       262.517 13.143
## Warning: 1 (0.943%) p_waic estimates greater than 0.4. We recommend trying
## loo instead.

# Podemos visualizar la distribución posterior de los parámetros extrayéndolos del modelo:
# plot(density(post_modelo_ordinal$beta))

scores_by_category
## 
##        1        2        3        4        5 
## 27.85853 10.38147 26.83944 27.67394 13.24662
table(mydata$Indicador)
## 
##  1  2  3  4  5 
## 28 10 28 29 11

# Parece que el número de veces que se escoje cada categoría en el dataset y en nuestras simulaciones son bastante similares.

scores_by_category_intervencion
## 
##         1         2         3         4         5 
## 18.549781  4.659594 11.835406  9.751594  2.203625
table(mydata$Indicador[mydata$Grupo == 1])
## 
##  1  2  3  4  5 
## 19  4 12 11  1

scores_by_category_control
## 
##         1         2         3         4         5 
##  9.308750  5.721875 15.004031 17.922344 11.043000
table(mydata$Indicador[mydata$Grupo == 0])
## 
##  1  2  3  4  5 
##  9  6 16 18 10

# Si estas predicciones no son buenas, entonces nuestro modelo no es una adecuada representación del proceso que ha generado las observaciones y debemos expandirlo con más parámetroso ajustar otro modelo y compararlo mediante WAIC o LOO. Si WAIC o LOO son menores para un determinado modelo, las predicciones son mejores.</code></pre>
</div>
<div id="estimacion-de-los-efectos-naturales" class="section level1">
<h1>Estimación de los efectos naturales</h1>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> En la siguiente figura se pueden observar las distribuciones posteriores de los efectos.</p>
<pre class="r"><code>Intercepto_1 &lt;- post_modelo_ordinal$Intercepts[, 1]
Intercepto_2 &lt;- post_modelo_ordinal$Intercepts[, 2]
Intercepto_3 &lt;- post_modelo_ordinal$Intercepts[, 3]
Intercepto_4 &lt;- post_modelo_ordinal$Intercepts[, 4]
beta_X1 &lt;- post_modelo_ordinal$betas[, 1]
beta_X2 &lt;- post_modelo_ordinal$betas[, 2]
beta_X3 &lt;- post_modelo_ordinal$betas[, 3]
beta_X4 &lt;- post_modelo_ordinal$betas[, 4]
beta_M &lt;- post_modelo_ordinal$beta
M1 &lt;- post_modelo_betabinomial$M1
M0 &lt;- post_modelo_betabinomial$M0
Y1M0 &lt;- Y1M1 &lt;- Y0M0 &lt;- Y0M1 &lt;- array(NA, dim = c(106, 5, 32000))
set.seed(1)
for(i in 1:32000) {
  Y1M0[1:106, 1:5, i] &lt;- predictPO(Si = M0[i, ], Grupo = 1, Intercepto_1[i], Intercepto_2[i], Intercepto_3[i],
                  Intercepto_4[i], beta_X1[i], beta_X2[i], beta_X3[i], beta_X4[i], beta_M[i])
  Y1M1[1:106, 1:5, i] &lt;- predictPO(Si = M1[i, ], Grupo = 1, Intercepto_1[i], Intercepto_2[i], Intercepto_3[i],
                  Intercepto_4[i], beta_X1[i], beta_X2[i], beta_X3[i], beta_X4[i], beta_M[i])
  Y0M0[1:106, 1:5, i] &lt;- predictPO(Si = M0[i, ], Grupo = 0, Intercepto_1[i], Intercepto_2[i], Intercepto_3[i],
                  Intercepto_4[i], beta_X1[i], beta_X2[i], beta_X3[i], beta_X4[i], beta_M[i])
  Y0M1[1:106, 1:5, i] &lt;- predictPO(Si = M1[i, ], Grupo = 0, Intercepto_1[i], Intercepto_2[i], Intercepto_3[i],
                  Intercepto_4[i], beta_X1[i], beta_X2[i], beta_X3[i], beta_X4[i], beta_M[i])
}

NDE &lt;- Y1M0 - Y0M0 # Efecto natural directo.
NIE &lt;- Y0M1 - Y0M0 # Efecto natural indirecto.

NDE_estimate &lt;- NIE_estimate &lt;- NA
for(i in 1:5) NDE_estimate[i] &lt;- mean(NDE[, i, ]) # Efecto natural directo promediado.
for(i in 1:5) NIE_estimate[i] &lt;- mean(NIE[, i, ]) # Efecto natural indirecto promediado.

NDE_posterior_mean &lt;- NIE_posterior_mean &lt;- matrix(NA, nrow = 32000, ncol = 5)
for(x in 1:5) for(i in 1:32000) NDE_posterior_mean[i, x] &lt;- mean(NDE[, x, i]) # Media del efecto natural directo promediado.
for(x in 1:5) for(i in 1:32000) NIE_posterior_mean[i, x] &lt;- mean(NIE[, x, i]) # Media del efecto natural indirecto promediado.

posterior_NDE &lt;- as.data.frame(NDE_posterior_mean)
names(posterior_NDE) &lt;- paste(&quot;Categoría&quot;, seq(1:5), sep = &quot; &quot;)
posterior_NDE &lt;- gather(posterior_NDE, Categoría, value, c(&quot;Categoría 1&quot;, &quot;Categoría 2&quot;, &quot;Categoría 3&quot;, &quot;Categoría 4&quot;, &quot;Categoría 5&quot;) )
plot10 &lt;- ggplot(posterior_NDE, aes(value, fill = Categoría)) + theme_gray() + 
  geom_density(alpha = 0.4) +
  scale_x_continuous(name = NULL, limits = c(-0.3, 0.4), round(seq(-0.3, 0.4, 0.1), 1)) +
  scale_y_continuous(name = &quot;Densidad&quot;, limits = c(0, 10), seq(0, 10, 1), expand = c(0.03, 0)) +
  theme(axis.text.x = element_text(size = 12), axis.title.x = element_text(size = 15.5),
        axis.text.y = element_text(size = 12), axis.title.y = element_text(size = 15.5)) +
  theme(axis.text.x = element_text(margin = unit(c(3, 0, 0, 0), &quot;mm&quot;), colour = &quot;black&quot;),
        axis.text.y = element_text(margin = unit(c(0, 3, 0, 0), &quot;mm&quot;), colour = &quot;black&quot;)) +
  theme(axis.title.x = element_text(margin = unit(c(5, 0, 0, 0), &quot;mm&quot;), colour = &quot;black&quot;),
        axis.title.y = element_text(margin = unit(c(0, 5, 0, 0), &quot;mm&quot;), colour = &quot;black&quot;)) +
  theme(axis.ticks.x = element_line(size = 0.6), 
        axis.ticks.y = element_line(size = 0.6)) +
  theme(legend.background = element_rect(fill = &quot;transparent&quot;)) +
  theme(panel.border = element_rect(fill = NA), axis.ticks.length = unit(0.2, &quot;cm&quot;)) +
  theme(legend.position = c(0.85, 0.5), legend.text=element_text(size = 12)) +
  guides(fill = guide_legend(title = NULL)) +
  annotate(&quot;text&quot;, x = -0.2, y = 8.25, label = &quot;Efecto Natural \n Directo&quot;, parse = F, colour = &quot;black&quot;, size = 5)

posterior_NIE &lt;- as.data.frame(NIE_posterior_mean)
names(posterior_NIE) &lt;- paste(&quot;Categoría&quot;, seq(1:5), sep = &quot; &quot;)
posterior_NIE &lt;- gather(posterior_NIE, Categoría, value, c(&quot;Categoría 1&quot;, &quot;Categoría 2&quot;, &quot;Categoría 3&quot;, &quot;Categoría 4&quot;, &quot;Categoría 5&quot;) )
plot11 &lt;- ggplot(posterior_NIE, aes(value, fill = Categoría)) + theme_gray() + 
  geom_density(alpha = 0.4) +
  scale_x_continuous(name = NULL, limits = c(-0.3, 0.4), round(seq(-0.3, 0.4, 0.1), 1)) +
  scale_y_continuous(name = &quot;Densidad&quot;, limits = c(0, 25), seq(0, 25, 5), expand = c(0.03, 0)) +
  theme(axis.text.x = element_text(size = 12), axis.title.x = element_text(size = 15.5),
        axis.text.y = element_text(size = 12), axis.title.y = element_text(size = 15.5)) +
  theme(axis.text.x = element_text(margin = unit(c(3, 0, 0, 0), &quot;mm&quot;), colour = &quot;black&quot;),
        axis.text.y = element_text(margin = unit(c(0, 3, 0, 0), &quot;mm&quot;), colour = &quot;black&quot;)) +
  theme(axis.title.x = element_text(margin = unit(c(5, 0, 0, 0), &quot;mm&quot;), colour = &quot;black&quot;),
        axis.title.y = element_text(margin = unit(c(0, 5, 0, 0), &quot;mm&quot;), colour = &quot;black&quot;)) +
  theme(axis.ticks.x = element_line(size = 0.6), 
        axis.ticks.y = element_line(size = 0.6)) +
  theme(legend.background = element_rect(fill = &quot;transparent&quot;)) +
  theme(panel.border = element_rect(fill = NA), axis.ticks.length = unit(0.2, &quot;cm&quot;)) +
  theme(legend.position = c(0.85, 0.5), legend.text=element_text(size = 12)) +
  guides(fill = guide_legend(title = NULL)) +
  annotate(&quot;text&quot;, x = -0.2, y = 20, label = &quot;Efecto Natural \n Indirecto&quot;, parse = F, colour = &quot;black&quot;, size = 5)

posterior_TE &lt;- as.data.frame(NIE_posterior_mean + NDE_posterior_mean)
names(posterior_TE) &lt;- paste(&quot;Categoría&quot;, seq(1:5), sep = &quot; &quot;)
posterior_TE &lt;- gather(posterior_TE, Categoría, value, c(&quot;Categoría 1&quot;, &quot;Categoría 2&quot;, &quot;Categoría 3&quot;, &quot;Categoría 4&quot;, &quot;Categoría 5&quot;) )
plot12 &lt;- ggplot(posterior_TE, aes(value, fill = Categoría)) + theme_gray() + 
  geom_density(alpha = 0.4) +
  scale_x_continuous(name = NULL, limits = c(-0.5, 0.5), round(seq(-0.5, 0.5, 0.1), 1)) +
  scale_y_continuous(name = &quot;Densidad&quot;, limits = c(0, 10.3), seq(0, 10, 1), expand = c(0.03, 0)) +
  theme(axis.text.x = element_text(size = 12), axis.title.x = element_text(size = 15.5),
        axis.text.y = element_text(size = 12), axis.title.y = element_text(size = 15.5)) +
  theme(axis.text.x = element_text(margin = unit(c(3, 0, 0, 0), &quot;mm&quot;), colour = &quot;black&quot;),
        axis.text.y = element_text(margin = unit(c(0, 3, 0, 0), &quot;mm&quot;), colour = &quot;black&quot;)) +
  theme(axis.title.x = element_text(margin = unit(c(5, 0, 0, 0), &quot;mm&quot;), colour = &quot;black&quot;),
        axis.title.y = element_text(margin = unit(c(0, 5, 0, 0), &quot;mm&quot;), colour = &quot;black&quot;)) +
  theme(axis.ticks.x = element_line(size = 0.6), 
        axis.ticks.y = element_line(size = 0.6)) +
  theme(legend.background = element_rect(fill = &quot;transparent&quot;)) +
  theme(panel.border = element_rect(fill = NA), axis.ticks.length = unit(0.2, &quot;cm&quot;)) +
  theme(legend.position = c(0.85, 0.7), legend.text=element_text(size = 12)) +
  guides(fill = guide_legend(title = NULL)) +
  annotate(&quot;text&quot;, x = -0.35, y = 8.5, label = &quot;Efecto Total&quot;, parse = F, colour = &quot;black&quot;, size = 5)

# Distribución posterior de los efectos para cada categoría: 
grid.arrange(plot10, plot11, plot12, padding = unit(2, &quot;line&quot;),
             bottom = textGrob(&quot;Incremento/decremento de probabilidad&quot;, gp = gpar(fontsize = 15.5),  vjust = 0.8, hjust = 0.4))</code></pre>
<p><img src="TFG_files/figure-html/Bayesian_Effects_2-1.png" width="768" style="display: block; margin: auto;" /></p>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> Para estimar la probabilidad de que el efecto indirecto de la administración del fármaco sea mayor o menor que 0 tan solo debemos calcular la proporción de muestras que es superior a 0 para cualquier categoría:</p>
<pre class="r"><code># Con las muestras obtenidas podemos computar la probabilidad de que el efecto natural indirecto sea mayor a 0 para cada categoría:
prob_1 &lt;- mean(posterior_NIE$value[posterior_NIE$Categoría == &quot;Categoría 1&quot;] &gt; 0)
prob_2 &lt;- mean(posterior_NIE$value[posterior_NIE$Categoría == &quot;Categoría 2&quot;] &gt; 0)
prob_3 &lt;- mean(posterior_NIE$value[posterior_NIE$Categoría == &quot;Categoría 3&quot;] &gt; 0)
prob_4 &lt;- mean(posterior_NIE$value[posterior_NIE$Categoría == &quot;Categoría 4&quot;] &gt; 0)
prob_5 &lt;- mean(posterior_NIE$value[posterior_NIE$Categoría == &quot;Categoría 5&quot;] &gt; 0)
prob_NIE_above_0 &lt;- data.frame(prob_1, prob_2, prob_3, prob_4, prob_5)
colnames(prob_NIE_above_0) &lt;- paste(&quot;Categoría&quot;, seq(1:5), sep = &quot; &quot;)
rownames(prob_NIE_above_0) &lt;- &quot;Probabilidad&quot;

kable(t(prob_NIE_above_0), digits = 5, align = &quot;c&quot;) %&gt;%
  kable_styling(bootstrap_options = &quot;striped&quot;, full_width = F)</code></pre>
<table class="table table-striped" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:center;">
Probabilidad
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Categoría 1
</td>
<td style="text-align:center;">
0.99881
</td>
</tr>
<tr>
<td style="text-align:left;">
Categoría 2
</td>
<td style="text-align:center;">
0.99172
</td>
</tr>
<tr>
<td style="text-align:left;">
Categoría 3
</td>
<td style="text-align:center;">
0.57953
</td>
</tr>
<tr>
<td style="text-align:left;">
Categoría 4
</td>
<td style="text-align:center;">
0.00188
</td>
</tr>
<tr>
<td style="text-align:left;">
Categoría 5
</td>
<td style="text-align:center;">
0.00144
</td>
</tr>
</tbody>
</table>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> Según estos resultados, que coinciden con el de los análisis anteriores, parece razonable concluir que esta variable mediacional aumenta la probabilidad de puntuar en las categorías 1 y 2 en detrimento de las categorías 4 y 5.</p>
<p><br></p>
</div>
<div id="discusion" class="section level1">
<h1>Discusión</h1>
<p><br></p>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> En este manuscrito se han tratado brevemente cuatro métodos populares con los que analizar datos experimentales en psicología. Sin embargo, existe una gran diferencia entre ellos que suele pasar desapercibida. Entre los análisis frecuentistas, mientras que los tests de equivalencia, superioridad e inferioridad son meramente instrumentos para guiar el comportamiento del investigador a largo plazo de manera que no consuma sus recursos sin obtener resultados que considera de relevancia, la aproximación descrita en <span class="citation">Mayo and Cox (2006)</span> entraña toda una filosofía de la ciencia aplicada a nivel estadístico. Esta filosofía declara que se puede obtener un nivel de evidencia para cada posible valor del parámetro tomando en consideración la capacidad del test, en términos de potencia estadística, para descubrir discrepancias entre las predicciones del modelo nulo y los datos.</p>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> Por otra parte, la inferencia bayesiana reconceptualidad el término probabilidad para dotarle de una subjetividad que es introducida en forma de distribuciones probabilísticas a priori. Quienes advocan por considerar que una medida de evidencia es manifestada en forma de factor de Bayes, consideran que dicha subjetividad se corresponde con la creencia que el investigador otorga a cada hipótesis que quiere contrastar y el nivel de evidencia viene determinada por el impacto que los datos ejercen sobre dicha creencia. Una implicación inmediata de esta perspectiva requiere que dicha evidencia siempre sea de naturaleza comparativa pues se corresponde con la razón entre las predicciones que distintos modelo realizan sobre los datos. Por el contrario, otros bayesianos prefieren concebir la subjetividad como un conocimiento previo sobre la distribución del parámetro o una manifestación de su incertidumbre que regulariza los resultados. Para estos, las distribuciones posteriores aportan la evidencia misma, no es necesario establecer creencias sobre hipótesis y compararlas. Además, dado que el objetivo es regularizar los resultados sancionando valores improbables o imposibles del parámetro, una recomendación frecuente es analizar los datos varias veces modificando las distribuciones a priori y observar cómo afectan a las posteriores (<em>sensitivity analysis</em>).</p>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> El autor de este manuscrito ha validado los modelos empleados simulando datos y recuperando los parámetros a partir de ellos. En este proceso no ha sido necesario establecer probabilidades a priori sino tener la certeza de que, fueran los modelos incorrectos, estos no habrían recuperado con alta probabilidad los verdaderos valores del parámetro. Asumiendo que incluso los bayesianos validan sus modelos de esta forma, es posible que el enfoque desarrollado por Deborah Mayo para conceptualizar el término evidencia sea el más adecuado. De hecho, algunos importantes autores bayesianos han intentado incluir una parte de la filosofía de Mayo en la suya <span class="citation">(Andrew and Rohilla, n.d.)</span> a través de la comprobación de predicciones posteriores (<em>posterior predictive checks</em>). Resumidamente, este procedimiento consiste en generar nuevos datos a partir del modelo bayesiano y comprobar si estas predicciones son similares a los datos observados. Si esto no es así, se considera que el modelo es falsado. Sin embargo, no está claro en qué medida esta técnica de falsación permite garantizar inferencias con un determinado rigor. Adicionalmente, aún persisten diferencias que incluso involucran el mismo diseño experimental: la estadística frecuentista requiere que los diseños experimentales sean completados de acuerdo a un plan previo sin considerar cómo se va desarrollando la investigación mientras que los bayesianos permiten detener la recogida de datos una vez se ha obtenido, a juicio del analista, una cantidad de evidencia suficiente <span class="citation">(Rouder 2014)</span>.</p>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> Sea de una u otra forma, los investigadores en psicología deben tener presente las diferencias que entrañan los diversos métodos que comúnmente son empleados en la literatura pues suelen diferir en su conceptualización del término evidencia, el tipo de asunciones que establecen para validar los modelos e incluso afectan al propio diseño experimental.</p>
<p><br></p>
</div>
<div id="paquetes-r-empleados" class="section level1">
<h1>Paquetes R empleados</h1>
<p><br></p>
<p><span class="math inline">\({\;\;\;\;\;\;}\)</span> A continuación se citan los principales paquetes R empleados: <span class="citation">Auguie (2017)</span>, <span class="citation">Barrett (2018)</span>, <span class="citation">Gabry and Mahr (2017)</span>, <span class="citation">Gronau and Singmann (2017)</span>, <span class="citation">Meschiari (2015)</span>, <span class="citation">Pedersen (2017)</span>, <span class="citation">R Core Team (2018)</span>, <span class="citation">Stan Development Team (2017)</span>, <span class="citation">Stan Development Team (2018)</span>, <span class="citation">Textor and van der Zander (2016)</span>, <span class="citation">Vehtari et al. (2018)</span>, <span class="citation">Wickham (2016)</span>, <span class="citation">Wickham (2017)</span>, <span class="citation">Yee (2018)</span>.</p>
<p><br></p>
</div>
<div id="informacion-de-la-sesion" class="section level1">
<h1>Información de la sesión</h1>
<p><br></p>
<pre class="r"><code>sessionInfo()
## R version 3.4.4 (2018-03-15)
## Platform: x86_64-pc-linux-gnu (64-bit)
## Running under: Linux Mint 18.3
## 
## Matrix products: default
## BLAS: /usr/lib/openblas-base/libblas.so.3
## LAPACK: /usr/lib/libopenblasp-r0.2.18.so
## 
## locale:
##  [1] LC_CTYPE=es_ES.UTF-8       LC_NUMERIC=C              
##  [3] LC_TIME=es_ES.UTF-8        LC_COLLATE=es_ES.UTF-8    
##  [5] LC_MONETARY=es_ES.UTF-8    LC_MESSAGES=es_ES.UTF-8   
##  [7] LC_PAPER=es_ES.UTF-8       LC_NAME=C                 
##  [9] LC_ADDRESS=C               LC_TELEPHONE=C            
## [11] LC_MEASUREMENT=es_ES.UTF-8 LC_IDENTIFICATION=C       
## 
## attached base packages:
##  [1] grid      splines   stats4    stats     graphics  grDevices utils    
##  [8] datasets  methods   base     
## 
## other attached packages:
##  [1] bindrcpp_0.2.2       BayesFactor_0.9.12-2 Matrix_1.2-14       
##  [4] coda_0.19-1          kableExtra_0.9.0     knitr_1.20          
##  [7] patchwork_0.0.1      ggdag_0.1.1.9000     dagitty_0.2-2       
## [10] latex2exp_0.4.0      gridExtra_2.3        bayesplot_1.5.0.9000
## [13] VGAM_1.0-5           shinystan_2.5.0      shiny_1.0.5         
## [16] loo_2.0.0            bridgesampling_0.4-0 rstan_2.17.3        
## [19] StanHeaders_2.17.2   forcats_0.3.0        stringr_1.3.0       
## [22] dplyr_0.7.5          purrr_0.2.4          readr_1.1.1         
## [25] tidyr_0.8.0          tibble_1.4.2         ggplot2_2.2.1.9000  
## [28] tidyverse_1.2.1     
## 
## loaded via a namespace (and not attached):
##  [1] colorspace_1.3-2     deldir_0.1-14        ggridges_0.5.0      
##  [4] rsconnect_0.8.8      rprojroot_1.3-2      markdown_0.8        
##  [7] base64enc_0.1-3      rstudioapi_0.7       MatrixModels_0.4-1  
## [10] ggrepel_0.7.0        DT_0.3               mvtnorm_1.0-7       
## [13] lubridate_1.7.3      xml2_1.2.0           mnormt_1.5-5        
## [16] shinythemes_1.1.1    polyclip_1.6-1       jsonlite_1.5        
## [19] broom_0.4.3          ggforce_0.1.1        compiler_3.4.4      
## [22] httr_1.3.1           backports_1.1.2      assertthat_0.2.0    
## [25] lazyeval_0.2.1       cli_1.0.0            later_0.7.2         
## [28] tweenr_0.1.5         htmltools_0.3.6      tools_3.4.4         
## [31] igraph_1.2.1         gtable_0.2.0         glue_1.2.0          
## [34] reshape2_1.4.3       V8_1.5               Rcpp_0.12.17        
## [37] cellranger_1.1.0     nlme_3.1-137         udunits2_0.13       
## [40] crosstalk_1.0.0      ggraph_1.0.0.9999    psych_1.7.8         
## [43] rvest_0.3.2          mime_0.5             miniUI_0.1.1        
## [46] gtools_3.5.0         MASS_7.3-50          zoo_1.8-1           
## [49] scales_0.5.0.9000    tidygraph_1.0.0.9999 colourpicker_1.0    
## [52] hms_0.4.1            promises_1.0.1       Brobdingnag_1.2-4   
## [55] parallel_3.4.4       inline_0.3.14        curl_3.2            
## [58] yaml_2.1.19          pbapply_1.3-4        stringi_1.1.6       
## [61] highr_0.6            dygraphs_1.1.1.4     boot_1.3-20         
## [64] rlang_0.2.0.9001     pkgconfig_2.0.1      matrixStats_0.53.1  
## [67] evaluate_0.10.1      lattice_0.20-35      bindr_0.1.1         
## [70] labeling_0.3         htmlwidgets_1.0      tidyselect_0.2.4    
## [73] plyr_1.8.4           magrittr_1.5         R6_2.2.2            
## [76] mgcv_1.8-23          pillar_1.1.0         haven_1.1.1         
## [79] foreign_0.8-70       withr_2.1.2          units_0.5-1         
## [82] xts_0.10-1           modelr_0.1.2         crayon_1.3.4        
## [85] rmarkdown_1.9        viridis_0.5.1        readxl_1.0.0        
## [88] threejs_0.3.1        digest_0.6.15        xtable_1.8-2        
## [91] httpuv_1.4.2         munsell_0.4.3        viridisLite_0.3.0   
## [94] concaveman_1.0.0     shinyjs_1.0</code></pre>
<p><br></p>
</div>
<div id="referencias" class="section level1">
<h1>Referencias</h1>
<p><br></p>
<div id="refs" class="references">
<div id="ref-Andrew">
<p>Andrew, Gelman, and Shalizi Cosma Rohilla. n.d. “Philosophy and the Practice of Bayesian Statistics.” <em>British Journal of Mathematical and Statistical Psychology</em> 66 (1): 8–38. doi:<a href="https://doi.org/10.1111/j.2044-8317.2011.02037.x">10.1111/j.2044-8317.2011.02037.x</a>.</p>
</div>
<div id="ref-Auguie2017">
<p>Auguie, Baptiste. 2017. <em>GridExtra: Miscellaneous Functions for “Grid” Graphics</em>. <a href="https://CRAN.R-project.org/package=gridExtra" class="uri">https://CRAN.R-project.org/package=gridExtra</a>.</p>
</div>
<div id="ref-Banks2016">
<p>Banks, George C., Steven G. Rogelberg, Haley M. Woznyj, Ronald S. Landis, and Deborah E. Rupp. 2016. “Editorial: Evidence on Questionable Research Practices: The Good, the Bad, and the Ugly.” <em>Journal of Business and Psychology</em> 31 (3): 323–38. doi:<a href="https://doi.org/10.1007/s10869-016-9456-7">10.1007/s10869-016-9456-7</a>.</p>
</div>
<div id="ref-Barberia2018">
<p>Barberia, Elisabet AND Matute, Itxaso AND Tubau. 2018. “A Short Educational Intervention Diminishes Causal Illusions and Specific Paranormal Beliefs in Undergraduates.” <em>PLOS ONE</em> 13 (1). Public Library of Science: 1–14. doi:<a href="https://doi.org/10.1371/journal.pone.0191907">10.1371/journal.pone.0191907</a>.</p>
</div>
<div id="ref-Barrett2018">
<p>Barrett, Malcolm. 2018. <em>Ggdag: Analyze and Create Elegant Directed Acyclic Graphs</em>. <a href="https://github.com/malcolmbarrett/ggdag" class="uri">https://github.com/malcolmbarrett/ggdag</a>.</p>
</div>
<div id="ref-Gabry2017">
<p>Gabry, Jonah, and Tristan Mahr. 2017. <em>Bayesplot: Plotting for Bayesian Models</em>. <a href="https://CRAN.R-project.org/package=bayesplot" class="uri">https://CRAN.R-project.org/package=bayesplot</a>.</p>
</div>
<div id="ref-Greenland2016">
<p>Greenland, Sander, Stephen J. Senn, Kenneth J. Rothman, John B. Carlin, Charles Poole, Steven N. Goodman, and Douglas G. Altman. 2016. “Statistical Tests, P Values, Confidence Intervals, and Power: A Guide to Misinterpretations.” <em>European Journal of Epidemiology</em> 31 (4): 337–50. doi:<a href="https://doi.org/10.1007/s10654-016-0149-3">10.1007/s10654-016-0149-3</a>.</p>
</div>
<div id="ref-Gronau2017">
<p>Gronau, Quentin F., and Henrik Singmann. 2017. <em>Bridgesampling: Bridge Sampling for Marginal Likelihoods and Bayes Factors</em>. <a href="https://CRAN.R-project.org/package=bridgesampling" class="uri">https://CRAN.R-project.org/package=bridgesampling</a>.</p>
</div>
<div id="ref-Imai2010">
<p>Imai, Kosuke, Luke Keele, and Dustin Tingley. 2010. “A General Approach to Causal Mediation Analysis.” <em>Psychological Methods</em>. Imai, Kosuke: Department of Politics, Princeton University, Princeton, NJ, US, 08544, kimai@princeton.edu: American Psychological Association. doi:<a href="https://doi.org/10.1037/a0020761">10.1037/a0020761</a>.</p>
</div>
<div id="ref-Lakens2017">
<p>Lakens, Daniël. 2017. “Equivalence Tests: A Practical Primer for T Tests, Correlations, and Meta-Analyses.” <em>Social Psychological and Personality Science</em> 8 (4): 355–62. doi:<a href="https://doi.org/10.1177/1948550617697177">10.1177/1948550617697177</a>.</p>
</div>
<div id="ref-Lindsay2015">
<p>Lindsay, D. Stephen. 2015. “Replication in Psychological Science.” <em>Psychol Sci</em> 26 (12). SAGE Publications Inc: 1827–32. doi:<a href="https://doi.org/10.1177/0956797615616374">10.1177/0956797615616374</a>.</p>
</div>
<div id="ref-Mayo2006a">
<p>Mayo, Deborah G., and D. R. Cox. 2006. “Frequentist Statistics as a Theory of Inductive Inference.” In <em>Optimality</em>, edited by Javier Rojo, Number 49:77–97. Lecture Notes–Monograph Series. Beachwood, Ohio, USA: Institute of Mathematical Statistics. doi:<a href="https://doi.org/10.1214/074921706000000400">10.1214/074921706000000400</a>.</p>
</div>
<div id="ref-Mayo2006">
<p>Mayo, Deborah G., and Aris Spanos. 2006. “Severe Testing as a Basic Concept in a Neyman–Pearson Philosophy of Induction.” <em>The British Journal for the Philosophy of Science</em> 57 (2): 323–57. doi:<a href="https://doi.org/10.1093/bjps/axl003">10.1093/bjps/axl003</a>.</p>
</div>
<div id="ref-Mayo2011">
<p>———. 2011. “Error Statistics.” In <em>Philosophy of Statistics</em>, edited by Prasanta S. Bandyopadhyay and Malcolm R. Forster, 7:153–98. Handbook of the Philosophy of Science. Amsterdam: North-Holland. doi:<a href="https://doi.org/https://doi.org/10.1016/B978-0-444-51862-0.50005-8">https://doi.org/10.1016/B978-0-444-51862-0.50005-8</a>.</p>
</div>
<div id="ref-Meschiari2015">
<p>Meschiari, Stefano. 2015. <em>Latex2exp: Use Latex Expressions in Plots</em>. <a href="https://CRAN.R-project.org/package=latex2exp" class="uri">https://CRAN.R-project.org/package=latex2exp</a>.</p>
</div>
<div id="ref-Morey2016">
<p>Morey, Richard D., Jan-Willem Romeijn, and Jeffrey N. Rouder. 2016. “The Philosophy of Bayes Factors and the Quantification of Statistical Evidence.” <em>Journal of Mathematical Psychology</em> 72: 6–18. doi:<a href="https://doi.org/https://doi.org/10.1016/j.jmp.2015.11.001">https://doi.org/10.1016/j.jmp.2015.11.001</a>.</p>
</div>
<div id="ref-Morris2017">
<p>Morris, Stefanie Dorough, James W. Grice, and Ryan A. Cox. 2017. “Scale Imposition as Quantitative Alchemy: Studies on the Transitivity of Neuroticism Ratings.” <em>Basic and Applied Social Psychology</em> 39 (1). Routledge: 1–18. doi:<a href="https://doi.org/10.1080/01973533.2016.1256288">10.1080/01973533.2016.1256288</a>.</p>
</div>
<div id="ref-Munafo2017">
<p>Munafò, Marcus R., Brian A. Nosek, Dorothy V. M. Bishop, Katherine S. Button, Christopher D. Chambers, Nathalie Percie du Sert, Uri Simonsohn, Eric-Jan Wagenmakers, Jennifer J. Ware, and John P. A. Ioannidis. 2017. “A Manifesto for Reproducible Science.” <em>Nature Human Behaviour</em> 1 (January). Macmillan Publishers Limited: 0021. <a href="http://dx.doi.org/10.1038/s41562-016-0021" class="uri">http://dx.doi.org/10.1038/s41562-016-0021</a>.</p>
</div>
<div id="ref-NP1933">
<p>Neyman, J., and E. S. Pearson. 1933. “IX. on the Problem of the Most Efficient Tests of Statistical Hypotheses.” <em>Philosophical Transactions of the Royal Society of London A: Mathematical, Physical and Engineering Sciences</em> 231 (694-706). The Royal Society: 289–337. doi:<a href="https://doi.org/10.1098/rsta.1933.0009">10.1098/rsta.1933.0009</a>.</p>
</div>
<div id="ref-Nuijten2015">
<p>Nuijten, Michèle B., Ruud Wetzels, Dora Matzke, Conor V. Dolan, and Eric-Jan Wagenmakers. 2015. “A Default Bayesian Hypothesis Test for Mediation.” <em>Behavior Research Methods</em> 47 (1): 85–97. doi:<a href="https://doi.org/10.3758/s13428-014-0470-2">10.3758/s13428-014-0470-2</a>.</p>
</div>
<div id="ref-OSC2015">
<p>Open Science Collaboration. 2015. “Estimating the Reproducibility of Psychological Science.” <em>Science</em> 349 (6251). American Association for the Advancement of Science. doi:<a href="https://doi.org/10.1126/science.aac4716">10.1126/science.aac4716</a>.</p>
</div>
<div id="ref-Pearl2014">
<p>Pearl, Judea. 2014. “Interpretation and Identification of Causal Mediation.” <em>Psychological Methods</em>. Pearl, Judea: Computer Science Department, University of California Los Angeles, Los Angeles, CA, US, 90095-1596, judea@cs.ucla.edu: American Psychological Association. doi:<a href="https://doi.org/10.1037/a0036434">10.1037/a0036434</a>.</p>
</div>
<div id="ref-Pedersen2017">
<p>Pedersen, Thomas Lin. 2017. <em>Patchwork: The Composer of Ggplots</em>. <a href="https://github.com/thomasp85/patchwork" class="uri">https://github.com/thomasp85/patchwork</a>.</p>
</div>
<div id="ref-Peterson1990">
<p>Peterson, Bercedis, and Frank E. Harrell. 1990. “Partial Proportional Odds Models for Ordinal Response Variables” 39 (2). [Wiley, Royal Statistical Society]: 205–17. <a href="http://www.jstor.org/stable/2347760" class="uri">http://www.jstor.org/stable/2347760</a>.</p>
</div>
<div id="ref-RCT2018">
<p>R Core Team. 2018. <em>R: A Language and Environment for Statistical Computing</em>. Vienna, Austria: R Foundation for Statistical Computing. <a href="https://www.R-project.org/" class="uri">https://www.R-project.org/</a>.</p>
</div>
<div id="ref-Rouder2014">
<p>Rouder, Jeffrey N. 2014. “Optional Stopping: No Problem for Bayesians.” <em>Psychonomic Bulletin &amp; Review</em> 21 (2): 301–8. doi:<a href="https://doi.org/10.3758/s13423-014-0595-4">10.3758/s13423-014-0595-4</a>.</p>
</div>
<div id="ref-Senn2002">
<p>Senn, Stephen. 2002. “A Comment on Replication, P-Values and Evidence S.N.Goodman, Statistics in Medicine 1992; 11:875-879.” <em>Statistics in Medicine</em> 21 (16). John Wiley &amp; Sons, Ltd.: 2437–44. doi:<a href="https://doi.org/10.1002/sim.1072">10.1002/sim.1072</a>.</p>
</div>
<div id="ref-SDT2017">
<p>Stan Development Team. 2017. “Shinystan: Interactive Visual and Numerical Diagnostics and Posterior Analysis for Bayesian Models.” <a href="http://mc-stan.org/" class="uri">http://mc-stan.org/</a>.</p>
</div>
<div id="ref-SDT2018">
<p>———. 2018. “RStan: The R Interface to Stan.” <a href="http://mc-stan.org/" class="uri">http://mc-stan.org/</a>.</p>
</div>
<div id="ref-Sterling1959">
<p>Sterling, Theodore D. 1959. “Publication Decisions and Their Possible Effects on Inferences Drawn from Tests of Significance–Or Vice Versa.” <em>Journal of the American Statistical Association</em> 54 (285). [American Statistical Association, Taylor &amp; Francis, Ltd.]: 30–34. <a href="http://www.jstor.org/stable/2282137" class="uri">http://www.jstor.org/stable/2282137</a>.</p>
</div>
<div id="ref-Textor2016">
<p>Textor, Johannes, and Benito van der Zander. 2016. <em>Dagitty: Graphical Analysis of Structural Causal Models</em>. <a href="https://CRAN.R-project.org/package=dagitty" class="uri">https://CRAN.R-project.org/package=dagitty</a>.</p>
</div>
<div id="ref-Trafimow2015">
<p>Trafimow, David, and Michael Marks. 2015. “Editorial.” <em>Basic and Applied Social Psychology</em> 37 (1). Routledge: 1–2. doi:<a href="https://doi.org/10.1080/01973533.2015.1012991">10.1080/01973533.2015.1012991</a>.</p>
</div>
<div id="ref-VanderWeele2016">
<p>VanderWeele, Tyler J., Yun Zhang, and Pilar Lim. 2016. “Brief Report: Mediation Analysis with an Ordinal Outcome.” <em>Epidemiology</em> 27 (5): –. <a href="https://journals.lww.com/epidem/Fulltext/2016/09000/Brief_Report___Mediation_Analysis_with_an_Ordinal.8.aspx" class="uri">https://journals.lww.com/epidem/Fulltext/2016/09000/Brief_Report___Mediation_Analysis_with_an_Ordinal.8.aspx</a>.</p>
</div>
<div id="ref-Vehtari2018">
<p>Vehtari, Aki, Jonah Gabry, Yuling Yao, and Andrew Gelman. 2018. “Loo: Efficient Leave-One-Out Cross-Validation and Waic for Bayesian Models.” <a href="https://CRAN.R-project.org/package=loo" class="uri">https://CRAN.R-project.org/package=loo</a>.</p>
</div>
<div id="ref-Wason1960">
<p>Wason, P. C. 1960. “On the Failure to Eliminate Hypotheses in a Conceptual Task.” <em>Quarterly Journal of Experimental Psychology</em> 12 (3). SAGE Publications: 129–40. doi:<a href="https://doi.org/10.1080/17470216008416717">10.1080/17470216008416717</a>.</p>
</div>
<div id="ref-Wetzels2009">
<p>Wetzels, Ruud, Jeroen G. W. Raaijmakers, Emöke Jakab, and Eric-Jan Wagenmakers. 2009. “How to Quantify Support for and Against the Null Hypothesis: A Flexible Winbugs Implementation of a Default Bayesian T Test.” <em>Psychonomic Bulletin &amp; Review</em> 16 (4): 752–60. doi:<a href="https://doi.org/10.3758/PBR.16.4.752">10.3758/PBR.16.4.752</a>.</p>
</div>
<div id="ref-Wickham2016">
<p>Wickham, Hadley. 2016. <em>Ggplot2: Elegant Graphics for Data Analysis</em>. Springer-Verlag New York. <a href="http://ggplot2.org" class="uri">http://ggplot2.org</a>.</p>
</div>
<div id="ref-Wickham2017">
<p>———. 2017. <em>Tidyverse: Easily Install and Load the ’Tidyverse’</em>. <a href="https://CRAN.R-project.org/package=tidyverse" class="uri">https://CRAN.R-project.org/package=tidyverse</a>.</p>
</div>
<div id="ref-Yates1951">
<p>Yates, F. 1951. “The Influence of Statistical Methods for Research Workers on the Development of the Science of Statistics.” <em>Journal of the American Statistical Association</em> 46 (253). Taylor &amp; Francis: 19–34. doi:<a href="https://doi.org/10.1080/01621459.1951.10500764">10.1080/01621459.1951.10500764</a>.</p>
</div>
<div id="ref-Yee2018">
<p>Yee, Thomas W. 2018. <em>VGAM: Vector Generalized Linear and Additive Models</em>. <a href="https://CRAN.R-project.org/package=VGAM" class="uri">https://CRAN.R-project.org/package=VGAM</a>.</p>
</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>En el <span class="citation">Open Science Collaboration (2015)</span> se volvieron a contrastar experimentalmente 97 hipótesis reportadas con resultados estadísticamente significativos (4 de las cuales tenían p-valores ligeramente por encima de 0.05), considerando como replicación la repetición de un p-valor menor a 0.05. Sin embargo, tras esta regla subyace una dicotomización arbitraria de la evidencia.<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>La razón de usar un parámetro grupal distinto para cada categoría se debe a que la asunción de que dichos coeficientes son equivalentes no está suficientemente garantizada.<a href="#fnref2">↩</a></p></li>
<li id="fn3"><p>Esta disposición a invertir los recursos puede depender de factores tan diferentes como el poder adquisitivo o la importancia subjetiva que el investigador asigna al tamaño del efecto. Se sugiere que, cuando el investigador carezca de razones teóricas para establecer el menor efecto de interés, se tome el efecto más pequeño que cuente con una razonable potencia estadística. Sin embargo, esta práctica es discutible ya que ante estimaciones con mucha incertidumbre (pequeño tamaño muestral) corremos el riesgo de incluir en la región de equivalencia valores que consideramos de práctica importancia.<a href="#fnref3">↩</a></p></li>
<li id="fn4"><p>Los límites no tienen por qué ser equivalentes en magnitud.<a href="#fnref4">↩</a></p></li>
<li id="fn5"><p>Una razón de momios de 0.83 corresponde a una disminución del 20% en los momios del grupo de intervención respecto al grupo de no intervención.<a href="#fnref5">↩</a></p></li>
<li id="fn6"><p>Aunque se suele pensar que ambas son irreconciliables.<a href="#fnref6">↩</a></p></li>
<li id="fn7"><p>Para una lectura sobre los frecuentes malentendidos que surgen al interpretar los intervalos de confianza se recomienda <span class="citation">Greenland et al. (2016)</span>.<a href="#fnref7">↩</a></p></li>
<li id="fn8"><p>Para <span class="math inline">\(\beta^\prime_{MY}\)</span> debe computarse el complementario ya que la dirección del efecto es opuesta.<a href="#fnref8">↩</a></p></li>
<li id="fn9"><p>Nótese que los valores de rigor al 97.5% coinciden con los límites de confianza del intervalo de los respectivos parámetros al 95%. Sin embargo, esta nueva interpretación y visualización nos aporta información sobre el grado de evidencia (rigor) con el que se puede inferir cualquier posible valor que pueden tomar los parámetros.<a href="#fnref9">↩</a></p></li>
<li id="fn10"><p>Se utiliza la distribución posterior de los parámetros, <span class="math inline">\(p(\theta \, | \, y)\)</span>, para computar el <em>marginal likelihood</em>, <span class="math inline">\(p(y) = \int p(y \, | \, \theta) \, p(\theta) \, d{\theta}\)</span>, a través de un algoritmo iterativo conocido como <em>bridge sampling</em>: <span class="math display">\[ \hat{p}(y) = \frac{\int p(y \, | \, \theta) \, p(\theta) \, h(\theta) \, g(\theta) \, d\theta}{\int h(\theta) \, g(\theta) \, p(\theta \, | \, y) \, d\theta} = \frac{E_{g(\theta)}[p(y \, | \, \theta) \, h(\theta)]}{E_{p(\theta \, | \, y)}[h(\theta) \, g(\theta)]} \]</span> donde <span class="math inline">\(\theta\)</span> es un vector de parámetros, <span class="math inline">\(h(\theta)\)</span> es la función que minimiza el error de predicción en el proceso iterativo y <span class="math inline">\(g(\theta)\)</span> es una distribución arbitraria pero que debe ser algo similar a la posterior. De esta manera, tomando muestras de <span class="math inline">\(g(\theta)\)</span> y de <span class="math inline">\(p(\theta \, | \, y)\)</span>, podemos aproximar el <em>marginal likelihood</em>. Una explicación más concisa puede encontrarse en <span class="citation">Gronau and Singmann (2017)</span>. <br> <span class="math inline">\({\;\;\;\;\;\;}\)</span> La importancia de esta técnica es vital porque hasta hace poco solo era posible calcular los factores de Bayes usando paquetes estadísticos con distribuciones a priori que ya venían dadas, es decir, hipótesis por defecto. Sin embargo, el reciente paquete R <em>bridgesampling</em> permite obtener el <em>marginal likelihood</em> de cualquier modelo que un analista pueda imaginar.<a href="#fnref10">↩</a></p></li>
</ol>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
